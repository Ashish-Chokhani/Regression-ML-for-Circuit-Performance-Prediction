{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv\n",
    "import subprocess\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generating files for delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Function to extract parameter values from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract parameter value from content\n",
    "def extract_parameter_value(file_content, parameter):\n",
    "    matches = re.findall(rf'\\b{parameter}\\s*=\\s*([\\d.e+-]+)', file_content)\n",
    "    if matches:\n",
    "        return matches[0], float(matches[1])  # Return the second occurrence\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Function to calculate mean and standard deviation for parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(file_path, parameter):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    _, mean = extract_parameter_value(content, parameter)\n",
    "    std = mean / 30  # Assuming a standard deviation of 1/30th of the mean\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Function to modify files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def modify_file(file_path, temp, supply, cqload, lmin, wmin, whichBlock, no_of_inputs):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.read()\n",
    "        lines = file.readlines()\n",
    "\n",
    "    data = re.sub(r'^dc TEMP .+$', f'dc TEMP {temp:.2f} {temp:.2f} {85}', data, flags=re.MULTILINE)\n",
    "    data = re.sub(r'^\\.PARAM SUPPLY=.+$', f'.PARAM SUPPLY={supply:.2f}', data, flags=re.MULTILINE)\n",
    "    data = re.sub(r'Cqload Vout gnd .+f', f'Cqload Vout gnd {cqload:.2f}f', data)\n",
    "    data = re.sub(r'\\.PARAM Lmin=.+$', f'.PARAM Lmin={lmin:.2f}n', data, flags=re.MULTILINE)\n",
    "    data = re.sub(r'\\.PARAM Wmin=.+$', f'.PARAM Wmin={wmin:.2f}n', data, flags=re.MULTILINE)\n",
    "    \n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    curBlock_Vin, curBlock_meas = 0, 0\n",
    "    cnt_Vin, cnt_meas = no_of_inputs, 2\n",
    "    for i in range(len(lines)):\n",
    "        if lines[i].startswith('*Vin1'):\n",
    "            curBlock_Vin += 1\n",
    "        \n",
    "        if curBlock_Vin == whichBlock and cnt_Vin >= 1:\n",
    "            if lines[i].startswith('*Vin1') or lines[i].startswith('*Vin2') or lines[i].startswith('*Vin3') or lines[i].startswith('*Vin4'):\n",
    "                lines[i] = lines[i][1:]\n",
    "                cnt_Vin -= 1\n",
    "        \n",
    "        if curBlock_meas // 2 == whichBlock - 1 and cnt_meas >= 1:\n",
    "            if lines[i].startswith('*.measure'):\n",
    "                lines[i] = lines[i][1:]\n",
    "                cnt_meas -= 1\n",
    "        \n",
    "        if lines[i].startswith('*.measure'):\n",
    "            curBlock_meas += 1\n",
    "    \n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 Function to modify leakage files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def modify_file_leakage(file_path, temp, supply, lmin, wmin, *Vin_values):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.read()\n",
    "        lines = file.readlines()\n",
    "\n",
    "    data = re.sub(r'^dc TEMP .+$', f'dc TEMP {temp:.2f} {temp:.2f} {85}', data, flags=re.MULTILINE)\n",
    "    data = re.sub(r'^\\.PARAM SUPPLY=.+$', f'.PARAM SUPPLY={supply:.2f}', data, flags=re.MULTILINE)\n",
    "    data = re.sub(r'\\.PARAM Lmin=.+$', f'.PARAM Lmin={lmin:.2f}n', data, flags=re.MULTILINE)\n",
    "    data = re.sub(r'\\.PARAM Wmin=.+$', f'.PARAM Wmin={wmin:.2f}n', data, flags=re.MULTILINE)\n",
    "    \n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    j = 0\n",
    "    for i in range(len(lines)):\n",
    "        if lines[i].startswith(f'Vin{j+1}'):\n",
    "            parts = lines[i].split()\n",
    "            parts[-1] = str(Vin_values[j])\n",
    "            lines[i] = ' '.join(parts) + '\\n'\n",
    "            j += 1\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.6 Function to run ngspice commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import re\n",
    "\n",
    "def run_ngspice(file_path):\n",
    "    output = subprocess.check_output(['ngspice', '-b', file_path]).decode('utf-8')\n",
    "    delay_lh_match = re.search(r'delay_lh\\s*=\\s*([\\d.e+-]+)', output)\n",
    "    delay_hl_match = re.search(r'delay_hl\\s*=\\s*([\\d.e+-]+)', output)\n",
    "    delay_lh = float(delay_lh_match.group(1)) if delay_lh_match else None\n",
    "    delay_hl = float(delay_hl_match.group(1)) if delay_hl_match else None\n",
    "    \n",
    "    return delay_lh, delay_hl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.7 Function to calculate delay for a file and save it as csv file\n",
    "\n",
    "Inputs:\n",
    "1. PTM file (.pm)\n",
    "2. Circuit Netlist (.net)\n",
    "3. Number of samples to generate\n",
    "4. CSV file path\n",
    "\n",
    "Output:\n",
    "1. Modified CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_delay(parameters, ptm_file, netlist_file, csv_file, no_of_inputs, df_samples):\n",
    "    \n",
    "    # Load file content\n",
    "    with open(ptm_file, 'r') as file:\n",
    "        original_content = file.read()\n",
    "        \n",
    "    with open(netlist_file, 'r') as file:\n",
    "        original_content_net = file.read()\n",
    "        \n",
    "    # Make a copy of the original content for modification\n",
    "    modified_content = original_content\n",
    "\n",
    "    # Replace parameter values in the original file with sampled values\n",
    "    with open(csv_file, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        header_row = ['TEMP', 'pvdd', 'Cqload','Lmin', 'Wmin', 'toxe_n', 'toxm_n', 'toxref_n', 'toxp_n', 'xj_n', 'ndep_n','toxe_p', 'toxm_p', 'toxref_p', 'toxp_p', 'xj_p', 'ndep_p']\n",
    "        for node in range(no_of_inputs):\n",
    "            header_row += [f'delay_node{chr(97 + node)}']\n",
    "        num_rows = sum(1 for _ in open(csv_file, 'r'))\n",
    "        if num_rows==0:\n",
    "            writer.writerow(header_row)\n",
    "            \n",
    "        try: \n",
    "            for i in range(len(df_samples)):\n",
    "                i+=max(0,num_rows-1)\n",
    "                row = []\n",
    "                \n",
    "                # Extracting samples from DataFrame\n",
    "                lmin = df_samples['lmin'][i]\n",
    "                wmin = df_samples['wmin'][i]\n",
    "                temp = df_samples['temp'][i]\n",
    "                supply = df_samples['supply'][i]\n",
    "                cqload = df_samples['cqload'][i]\n",
    "                \n",
    "                # Replace parameter values in the original file with sampled values\n",
    "                for param in parameters:\n",
    "                    nmos_value=df_samples[param+'_n'][i]\n",
    "                    pmos_value=df_samples[param+'_p'][i]\n",
    "                    modified_content = re.sub(rf'\\b{param}\\s*=\\s*([\\d.e+-]+)', f'{param} = {pmos_value:.6e}', modified_content, count=2)\n",
    "                    modified_content = re.sub(rf'\\b{param}\\s*=\\s*([\\d.e+-]+)', f'{param} = {nmos_value:.6e}', modified_content, count=1)   \n",
    "                with open(ptm_file, 'w') as file:\n",
    "                    file.write(modified_content)\n",
    "                    \n",
    "                delay_values = []\n",
    "                for node in range(no_of_inputs):\n",
    "                    modify_file(netlist_file, temp, supply, cqload, lmin, wmin, node+1, no_of_inputs)\n",
    "                    \n",
    "                    delay_lh, delay_hl = run_ngspice(netlist_file)\n",
    "                    \n",
    "                    with open(netlist_file, 'w') as file:\n",
    "                        file.write(original_content_net)\n",
    "                    \n",
    "                    delay_values.append((delay_hl+delay_lh)/2)\n",
    "                \n",
    "                row.extend([temp, supply, cqload, lmin * 1e-9, wmin * 1e-9])\n",
    "                row.extend([df_samples[param+'_n'][i] for param in parameters])\n",
    "                row.extend([df_samples[param+'_p'][i] for param in parameters])\n",
    "                row.extend(delay_values)\n",
    "                writer.writerow(row)\n",
    "    \n",
    "        finally:\n",
    "            # Restore original content of ptm_file and netlist_file\n",
    "            with open(ptm_file, 'w') as file:\n",
    "                file.write(original_content)\n",
    "                \n",
    "            with open(netlist_file, 'w') as file:\n",
    "                file.write(original_content_net)\n",
    "\n",
    "            print(f\"Samples generated and saved in {csv_file}. Original files restored.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Defining Parameters to search for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters from file\n",
    "parameters = [\n",
    "    'toxe', 'toxm', 'toxref','toxp', 'xj', 'ndep'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples=pd.read_csv('samples_45nm_MGK.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Generating Delay matrices for all files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Gates essential for C499 Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. INVERTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'INVERTER'\n",
    "file_name = 'INVERTER_delay.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "generate_delay(parameters,'INVERTER/45nm_MGK.pm', 'INVERTER/INVERTER.net', 'INVERTER/INVERTER_delay.csv',1,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. AND_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'AND'\n",
    "file_name = 'AND_2_delay.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "generate_delay(parameters,'AND/45nm_MGK.pm', 'AND/AND.net', 'AND/AND_2_delay.csv',2,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. AND_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Starting dynamic gmin stepping\n",
      "Trying gmin =   1.0000E-03 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-04 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-05 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-06 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-07 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-08 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-09 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-10 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-11 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-12 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-13 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-14 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-15 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-16 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-17 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-18 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-19 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-20 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-20 Note: One successful gmin step\n",
      "Note: Dynamic gmin stepping completed\n",
      "Note: Starting dynamic gmin stepping\n",
      "Trying gmin =   1.0000E-03 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-04 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-05 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-06 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-07 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-08 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-09 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-10 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-11 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-12 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-13 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-14 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-15 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-16 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-17 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-18 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-19 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-20 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-20 Note: One successful gmin step\n",
      "Note: Dynamic gmin stepping completed\n",
      "Note: Starting dynamic gmin stepping\n",
      "Trying gmin =   1.0000E-03 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-04 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-05 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-06 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-07 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-08 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-09 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-10 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-11 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-12 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-13 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-14 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-15 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-16 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-17 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-18 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-19 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-20 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-20 Note: One successful gmin step\n",
      "Note: Dynamic gmin stepping completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples generated and saved in AND_3/AND_3_delay.csv. Original files restored.\n"
     ]
    }
   ],
   "source": [
    "directory = 'AND_3'\n",
    "file_name = 'AND_3_delay.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "generate_delay(parameters,'AND_3/45nm_MGK.pm', 'AND_3/AND.net', 'AND_3/AND_3_delay.csv',3,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples generated and saved in XOR/XOR_delay.csv. Original files restored.\n"
     ]
    }
   ],
   "source": [
    "directory = 'XOR'\n",
    "file_name = 'XOR_delay.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "generate_delay(parameters,'XOR/45nm_MGK.pm', 'XOR/XOR.net', 'XOR/XOR_delay.csv',2,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. OR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'OR'\n",
    "file_name = 'OR_2_delay.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "generate_delay(parameters,'OR/45nm_MGK.pm', 'OR/OR.net', 'OR/OR_2_delay.csv',2,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Gates non-essential for C499 Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. NAND_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'NAND'\n",
    "# file_name = 'NAND_2_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'NAND/45nm_MGK.pm', 'NAND/NAND.net', 'NAND/NAND_2_delay.csv',2,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. NAND_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'NAND_3'\n",
    "# file_name = 'NAND_3_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'NAND_3/45nm_MGK.pm', 'NAND_3/NAND.net', 'NAND_3/NAND_3_delay.csv',3,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. NAND_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'NAND_4'\n",
    "# file_name = 'NAND_4_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'NAND_4/45nm_MGK.pm', 'NAND_4/NAND.net', 'NAND_4/NAND_4_delay.csv',4,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. NOR_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'NOR'\n",
    "# file_name = 'NOR_2_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'NOR/45nm_MGK.pm', 'NOR/NOR.net', 'NOR/NOR_2_delay.csv',2,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. NOR_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'NOR_3'\n",
    "# file_name = 'NOR_3_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'NOR_3/45nm_MGK.pm', 'NOR_3/NOR.net', 'NOR_3/NOR_3_delay.csv',3,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. NOR_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'NOR_4'\n",
    "# file_name = 'NOR_4_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'NOR_4/45nm_MGK.pm', 'NOR_4/NOR.net', 'NOR_4/NOR_4_delay.csv',4,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. AND_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'AND_4'\n",
    "# file_name = 'AND_4_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'AND_4/45nm_MGK.pm', 'AND_4/AND.net', 'AND_4/AND_4_delay.csv',4,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. A012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'A012'\n",
    "# file_name = 'A012_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'A012/45nm_MGK.pm', 'A012/A012.net', 'A012/A012_delay.csv',3,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. A022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'A022'\n",
    "# file_name = 'A022_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'A022/45nm_MGK.pm', 'A022/A022.net', 'A022/A022_delay.csv',4,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. A031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'A031'\n",
    "# file_name = 'A031_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'A031/45nm_MGK.pm', 'A031/A031.net', 'A031/A031_delay.csv',4,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. A0112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'A0112'\n",
    "# file_name = 'A0112_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'A0112/45nm_MGK.pm', 'A0112/A0112.net', 'A0112/A0112_delay.csv',4,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generating files for leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Generic numeric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def round_to_nearest(value, values_list):\n",
    "    return min(values_list, key=lambda x: abs(x - value))\n",
    "\n",
    "def round_gate_voltage(value):\n",
    "    if value < 0.55:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Function to extract voltage and current data from a SPICE simulation output file.\n",
    "\n",
    "**Inputs:**\n",
    "1. `filename`: The filename of the SPICE simulation output file.\n",
    "2. `ratio_list`: A list containing two values representing the W/L ratio for PMOS and NMOS transistors respectively.\n",
    "\n",
    "**Output:**\n",
    "1. `df`: A pandas DataFrame containing the extracted data with the following columns:\n",
    "    - `MOSFET Type`: Type of the MOSFET (either 'PMOS' or 'NMOS').\n",
    "    - `W_L Ratio`: W/L ratio of the MOSFET.\n",
    "    - `Drain Voltage`: Voltage at the drain terminal of the MOSFET.\n",
    "    - `Gate Voltage`: Voltage at the gate terminal of the MOSFET.\n",
    "    - `Source Voltage`: Voltage at the source terminal of the MOSFET.\n",
    "    - `Drain Current`: Current flowing through the drain terminal of the MOSFET.\n",
    "    - `Gate Current`: Current flowing through the gate terminal of the MOSFET.\n",
    "    - `Source Current`: Current flowing through the source terminal of the MOSFET.\n",
    "    - `Body Current`: Body current of the MOSFET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spice_data(filename, ratio_list):\n",
    "    text = os.popen(f\"ngspice {filename}\").read()\n",
    "    voltage_pattern = re.compile(r\"v\\((\\w+)\\) = ([\\d\\.\\-\\+e]+)\")\n",
    "    current_pattern = re.compile(r\"i\\((\\w+)\\) = ([\\d\\.\\-\\+e]+)\")\n",
    "\n",
    "    voltages = []\n",
    "    currents = []\n",
    "\n",
    "    for match in re.finditer(voltage_pattern, text):\n",
    "        voltages.append((match.group(1), float(match.group(2))))\n",
    "\n",
    "    for match in re.finditer(current_pattern, text):\n",
    "        currents.append((match.group(1), float(match.group(2))))\n",
    "\n",
    "    rows = []\n",
    "    \n",
    "    round_values = [i/20 for i in range(0, 23)]\n",
    "\n",
    "    # Determine MOSFET type based on the number of rows in the DataFrame\n",
    "    mosfet_type_list = ['PMOS'] * (len(voltages) // 6) + ['NMOS'] * (len(voltages) // 6)\n",
    "    # Calculate W_L ratio for PMOS and NMOS\n",
    "    pmos_ratio, nmos_ratio = ratio_list\n",
    "\n",
    "    for i in range(len(voltages) // 3):  # Assuming each MOSFET has 3 voltage values\n",
    "        index = i * 3\n",
    "        index_current = i * 4\n",
    "        mosfet_type = mosfet_type_list[i]\n",
    "        ratio = pmos_ratio if mosfet_type == 'PMOS' else nmos_ratio\n",
    "        rows.append({'MOSFET Type': mosfet_type,\n",
    "                     'W_L Ratio': ratio,\n",
    "                     'Drain Voltage': round_to_nearest(voltages[index][1], round_values),\n",
    "                     'Gate Voltage': round_gate_voltage(voltages[index+1][1]), # Assuming gate voltage is constant for all transistors\n",
    "                     'Source Voltage': round_to_nearest(voltages[index+2][1], round_values),\n",
    "                     'Drain Current': currents[index_current][1],\n",
    "                     'Gate Current': currents[index_current+1][1], # Assuming gate current is constant for all transistors\n",
    "                     'Source Current': currents[index_current+2][1],\n",
    "                     'Body Current': currents[index_current+3][1]})\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=['MOSFET Type', 'W_L Ratio', 'Drain Voltage', 'Gate Voltage', 'Source Voltage',\n",
    "                                     'Drain Current', 'Gate Current', 'Source Current', 'Body Current'])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Function to calculate the total leakage current of a MOSFET based on the true current values, terminal voltages, MOSFET type, and supply voltage.\n",
    "\n",
    "**Inputs:**\n",
    "1. `true_values`: A tuple containing the true values of drain current, gate current, source current, and body current.\n",
    "2. `drain_voltage`: Voltage at the drain terminal.\n",
    "3. `gate_voltage`: Voltage at the gate terminal.\n",
    "4. `source_voltage`: Voltage at the source terminal.\n",
    "5. `mos_type`: Type of the MOSFET ('PMOS' or 'NMOS').\n",
    "6. `supply`: Supply voltage.\n",
    "\n",
    "**Output:**\n",
    "1. `leakage_current`: The calculated total leakage current of the MOSFET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_leakage(true_values, drain_voltage, gate_voltage, source_voltage, mos_type,supply):\n",
    "    # Extracting true currents\n",
    "    true_drain_current, true_gate_current, true_source_current, true_body_current = true_values\n",
    "    \n",
    "    # Checking if the magnitudes of incoming currents match\n",
    "    \n",
    "    if mos_type == 'PMOS':\n",
    "        body_voltage=supply\n",
    "    else:\n",
    "        body_voltage=0   \n",
    "    \n",
    "    # Calculating outgoing currents based on terminal voltages and direction of current flow\n",
    "    incoming_currents = []\n",
    "    if mos_type == 'PMOS':\n",
    "        # For PMOS, drain is at a lower potential than gate or source\n",
    "        if (drain_voltage < source_voltage or drain_voltage < body_voltage) and true_drain_current < 0:\n",
    "            incoming_currents.append(abs(true_drain_current))\n",
    "        if (gate_voltage < source_voltage or gate_voltage < drain_voltage) and true_gate_current < 0:\n",
    "            incoming_currents.append(abs(true_gate_current))\n",
    "        if (source_voltage < drain_voltage or source_voltage < gate_voltage) and true_source_current < 0:\n",
    "            incoming_currents.append(abs(true_source_current))\n",
    "        if true_body_current < 0:\n",
    "            incoming_currents.append(abs(true_body_current))  # Body current always flows out\n",
    "    elif mos_type == 'NMOS':\n",
    "        # For NMOS, drain is at a higher potential than gate or source\n",
    "        if (drain_voltage > source_voltage or drain_voltage > gate_voltage) and true_drain_current < 0:\n",
    "            incoming_currents.append(abs(true_drain_current))\n",
    "        if (gate_voltage > source_voltage or gate_voltage > drain_voltage) and true_gate_current < 0:\n",
    "            incoming_currents.append(abs(true_gate_current))\n",
    "        if (source_voltage > drain_voltage or source_voltage > gate_voltage) and true_source_current < 0:\n",
    "            incoming_currents.append(abs(true_source_current))\n",
    "        if true_body_current < 0:\n",
    "            incoming_currents.append(abs(true_body_current))  # Body current always flows out\n",
    "    \n",
    "    # Calculating leakage current as the sum of outgoing currents\n",
    "    leakage_current = sum(incoming_currents)\n",
    "    return leakage_current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 Function to calculate the total leakage current for all rows in an original list of MOSFET data.\n",
    "\n",
    "**Inputs:**\n",
    "1. `original_list`: A list containing MOSFET data where each item is a list with the following format:\n",
    "    - `original_list[i][0]`: MOSFET type ('PMOS' or 'NMOS').\n",
    "    - `original_list[i][2]`: Drain voltage.\n",
    "    - `original_list[i][3]`: Gate voltage.\n",
    "    - `original_list[i][4]`: Source voltage.\n",
    "    - `original_list[i][5:9]`: True current values (drain current, gate current, source current, body current).\n",
    "2. `supply`: Supply voltage.\n",
    "\n",
    "**Output:**\n",
    "1. `total_leakage_current`: The sum of all calculated leakage currents for each row in the original list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_leakage_for_all_rows(original_list,supply):\n",
    "    all_leakage_currents = []\n",
    "    for i in range(len(original_list)):\n",
    "        leakage_current = calculate_leakage(original_list[i][5:9],\n",
    "                                            original_list[i][2],\n",
    "                                            original_list[i][3],\n",
    "                                            original_list[i][4],\n",
    "                                            original_list[i][0],supply)\n",
    "        all_leakage_currents.append(leakage_current)\n",
    "        \n",
    "    return sum(all_leakage_currents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.6 Function to generate leakage values and save it in a csv file\n",
    "\n",
    "Inputs:\n",
    "1. PTM file (.pm)\n",
    "2. Circuit Netlist (.net)\n",
    "3. Number of inputs in the circuit\n",
    "4. Number of samples to generate\n",
    "5. CSV file path\n",
    "6. Parameters\n",
    "\n",
    "Output:\n",
    "1. Modified CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "from itertools import product\n",
    "\n",
    "def generate_leakage(PM_file, netlist_file, no_of_inputs, csv_file_path, parameters, file_ratio, df_samples):\n",
    "    # Load file content\n",
    "    with open(PM_file, 'r') as file:\n",
    "        original_content = file.read()\n",
    "\n",
    "    with open(netlist_file, 'r') as file:\n",
    "        original_content_leakage = file.read()\n",
    "\n",
    "    # Make a copy of the original content for modification\n",
    "    modified_content = original_content\n",
    "\n",
    "    # Replace parameter values in the original file with sampled values\n",
    "    with open(csv_file_path, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        header_row = ['Vin_' + chr(65 + i) for i in range(no_of_inputs)] + ['TEMP', 'pvdd', 'Lmin', 'Wmin', 'toxe_n', 'toxm_n', 'toxref_n', 'toxp_n', 'xj_n', 'ndep_n','toxe_p', 'toxm_p', 'toxref_p', 'toxp_p', 'xj_p', 'ndep_p'] + ['Leakage_power']\n",
    "        num_rows = sum(1 for _ in open(csv_file_path, 'r'))\n",
    "        to_skip=(num_rows%(2**no_of_inputs))-1;\n",
    "        to_skip=(to_skip+(2**no_of_inputs))%2**no_of_inputs\n",
    "        if num_rows==0:\n",
    "            writer.writerow(header_row)\n",
    "            to_skip=0\n",
    "        skipped=0\n",
    "        try:\n",
    "            for i in range(len(df_samples)):\n",
    "                i+=max(0,num_rows-1)//2**(no_of_inputs)\n",
    "                lmin = df_samples['lmin'][i]\n",
    "                wmin = df_samples['wmin'][i]\n",
    "                temp = df_samples['temp'][i]\n",
    "                supply = df_samples['supply'][i]\n",
    "\n",
    "                # Replace parameter values in the original file with sampled values\n",
    "                for param in parameters:\n",
    "                    nmos_value=df_samples[param+'_n'][i]\n",
    "                    pmos_value=df_samples[param+'_p'][i]\n",
    "                    modified_content = re.sub(rf'\\b{param}\\s*=\\s*([\\d.e+-]+)', f'{param} = {pmos_value:.6e}', modified_content, count=2)\n",
    "                    modified_content = re.sub(rf'\\b{param}\\s*=\\s*([\\d.e+-]+)', f'{param} = {nmos_value:.6e}', modified_content, count=1)   \n",
    "                \n",
    "                # Save modified content back to the original file\n",
    "                with open(PM_file, 'w') as file:\n",
    "                    file.write(modified_content)\n",
    "                \n",
    "                \n",
    "\n",
    "                # Iterate over all possible combinations of input voltages\n",
    "                for Vin_values in product(range(2), repeat=no_of_inputs):\n",
    "                    if skipped<to_skip:\n",
    "                        skipped+=1\n",
    "                        continue\n",
    "                    input_values = [(supply if val == 1 else 0) for val in Vin_values]\n",
    "                    modify_file_leakage(netlist_file, temp, supply, lmin, wmin, *input_values)\n",
    "                    \n",
    "                    # Extracting voltage and current values from executing netlist\n",
    "                    file_df_extracted = extract_spice_data(netlist_file, file_ratio)\n",
    "                    leakage_currents = calculate_leakage_for_all_rows(file_df_extracted.values.tolist(), supply)\n",
    "\n",
    "                    row = list(Vin_values) + [temp, supply, lmin * 1e-9, wmin * 1e-9] + [df_samples[param+'_n'][i] for param in parameters]+[df_samples[param+'_p'][i] for param in parameters] + [leakage_currents * (supply + sum(Vin_values))]\n",
    "                    writer.writerow(row)\n",
    "                    \n",
    "        finally:\n",
    "\n",
    "            # Revert changes back to original values\n",
    "            with open(PM_file, 'w') as file:\n",
    "                file.write(original_content)\n",
    "\n",
    "            with open(netlist_file, 'w') as file:\n",
    "                file.write(original_content_leakage)\n",
    "\n",
    "            print(f\"Samples generated and saved in '{csv_file_path}'. Original files restored.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.7 Function for and gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "def calculate_and_or_gate_leakage(nand_file_path, inverter_file_path, output_file_path, no_of_inputs):\n",
    "    # Read the input CSV files\n",
    "    nand_df = pd.read_csv(nand_file_path)\n",
    "    inverter_df = pd.read_csv(inverter_file_path)\n",
    "\n",
    "    # Define the keys for the resulting DataFrame\n",
    "    nand_parameter_key = [f'Vin_{chr(65+i)}' for i in range(no_of_inputs)] + ['TEMP', 'pvdd', 'Lmin', 'Wmin', 'toxe_n', 'toxm_n', 'toxref_n', 'toxp_n', 'xj_n', 'ndep_n', 'toxe_p', 'toxm_p', 'toxref_p', 'toxp_p', 'xj_p', 'ndep_p']\n",
    "    and_df = pd.DataFrame({key: [] for key in nand_parameter_key + ['Leakage_power']})\n",
    "\n",
    "    # Define the key for leakage power\n",
    "    leakage_key = 'Leakage_power'\n",
    "\n",
    "    # Iterate over the rows of NAND_df\n",
    "    cur_pointer=0\n",
    "    for index, nand_row in nand_df.iterrows():\n",
    "        # Get the corresponding inverter input for the current NAND input combination\n",
    "        input_combination = nand_row[[f'Vin_{chr(65+i)}' for i in range(no_of_inputs)]].tolist()\n",
    "        inverter_input = 0 if all(bit == 1 for bit in input_combination) else 1\n",
    "        \n",
    "        \n",
    "        # Sum the leakage power of the NAND gate and the matching inverter\n",
    "        row_no=cur_pointer+(inverter_input==1)\n",
    "        total_leakage_power = nand_row[leakage_key] + inverter_df.loc[row_no,leakage_key]\n",
    "\n",
    "        # Append the values to the DataFrame\n",
    "        and_df = pd.concat([and_df, pd.DataFrame({**dict(nand_row), leakage_key: total_leakage_power}, index=[0])], ignore_index=True)\n",
    "        \n",
    "        if (index+1)%((2**no_of_inputs))==0:\n",
    "            cur_pointer += 2\n",
    "        \n",
    "\n",
    "    # Save the resulting DataFrame to a CSV file\n",
    "    and_df.to_csv(output_file_path, index=False)\n",
    "    \n",
    "    print(f\"Samples generated and saved in '{output_file_path}'. Original files restored.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Defining Parameters to search for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of parameters to search for\n",
    "parameters = [\n",
    "    'toxe', 'toxm', 'toxref','toxp', 'xj', 'ndep'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Generating Leakage matrices for all files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Gates essential for C499 Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. INVERTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'INVERTER'\n",
    "file_name = 'INVERTER_leakage.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "no_of_inputs = 1  # Number of inputs in the circuit\n",
    "rows_for_leakage=df_samples[max(0,num_rows-1)//(2**no_of_inputs):]\n",
    "\n",
    "generate_leakage('INVERTER/45nm_MGK.pm', 'INVERTER/INVERTER_leakage.net', no_of_inputs, 'INVERTER/INVERTER_leakage.csv',parameters,[2,1],rows_for_leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. NAND_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'NAND'\n",
    "file_name = 'NAND_2_leakage.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "no_of_inputs = 2  # Number of inputs in the circuit\n",
    "rows_for_leakage=df_samples[max(0,num_rows-1)//(2**no_of_inputs):]\n",
    "\n",
    "generate_leakage('NAND/45nm_MGK.pm', 'NAND/NAND_leakage.net', no_of_inputs, 'NAND/NAND_2_leakage.csv', parameters, [2,2],rows_for_leakage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. NAND_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'NAND_3'\n",
    "file_name = 'NAND_3_leakage.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "no_of_inputs = 3  # Number of inputs in the circuit\n",
    "rows_for_leakage=df_samples[max(0,num_rows-1)//(2**no_of_inputs):]\n",
    "\n",
    "generate_leakage('NAND_3/45nm_MGK.pm', 'NAND_3/NAND_leakage.net', no_of_inputs, 'NAND_3/NAND_3_leakage.csv',parameters,[2,3],rows_for_leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. NOR_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'NOR'\n",
    "file_name = 'NOR_2_leakage.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# NOR_2\n",
    "no_of_inputs = 2  # Number of inputs in the circuit\n",
    "rows_for_leakage=df_samples[max(0,num_rows-1)//(2**no_of_inputs):]\n",
    "\n",
    "generate_leakage('NOR/45nm_HP.pm', 'NOR/NOR_leakage.net', no_of_inputs, 'NOR/NOR_2_leakage.csv', parameters, [4, 1],rows_for_leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'XOR'\n",
    "file_name = 'XOR_leakage.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "no_of_inputs = 2  # Number of inputs in the circuit\n",
    "rows_for_leakage=df_samples[max(0,num_rows-1)//(2**no_of_inputs):]\n",
    "\n",
    "generate_leakage('XOR/45nm_MGK.pm', 'XOR/XOR_leakage.net', no_of_inputs, 'XOR/XOR_leakage.csv',parameters,[2,1],rows_for_leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. AND_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For AND2\n",
    "calculate_and_or_gate_leakage('NAND/NAND_2_leakage.csv', 'INVERTER/INVERTER_leakage.csv', 'AND/AND_2_leakage.csv',2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. AND_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For AND3\n",
    "calculate_and_or_gate_leakage('NAND_3/NAND_3_leakage.csv', 'INVERTER/INVERTER_leakage.csv', 'AND_3/AND_3_leakage.csv',3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. OR_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For AND2\n",
    "calculate_and_or_gate_leakage('NOR/NOR_2_leakage.csv', 'INVERTER/INVERTER_leakage.csv', 'OR/OR_2_leakage.csv',2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Gates non-essential for C499 Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. NAND_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'NAND_4'\n",
    "# file_name = 'NAND_4_leakage.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# no_of_inputs = 4  # Number of inputs in the circuit\n",
    "# rows_for_leakage=df_samples[max(0,num_rows-1)//(2**no_of_inputs):]\n",
    "\n",
    "# generate_leakage('NAND_4/45nm_MGK.pm', 'NAND_4/NAND_leakage.net', no_of_inputs, 'NAND_4/NAND_4_leakage.csv',parameters,[2,4],rows_for_leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. AND_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For AND4\n",
    "# calculate_and_or_gate_leakage('NAND_4/NAND_4_leakage.csv', 'INVERTER/INVERTER_leakage.csv', 'AND_4/AND_4_leakage.csv',4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. NOR_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'NOR_3'\n",
    "# file_name = 'NOR_3_leakage.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# # NOR_3\n",
    "# no_of_inputs = 3  # Number of inputs in the circuit\n",
    "# rows_for_leakage=df_samples[max(0,num_rows-1)//(2**no_of_inputs):]\n",
    "\n",
    "# generate_leakage('NOR_3/45nm_MGK.pm', 'NOR_3/NOR_leakage.net', no_of_inputs, 'NOR_3/NOR_3_leakage.csv', parameters, [6, 1],rows_for_leakage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. NOR_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'NOR_4'\n",
    "# file_name = 'NOR_4_leakage.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# no_of_inputs = 4  # Number of inputs in the circuit\n",
    "# rows_for_leakage=df_samples[max(0,num_rows-1)//(2**no_of_inputs):]\n",
    "\n",
    "# generate_leakage('NOR_4/45nm_MGK.pm', 'NOR_4/NOR_leakage.net', no_of_inputs, 'NOR_4/NOR_4_leakage.csv',parameters,[8,1],rows_for_leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. A012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'A012'\n",
    "# file_name = 'A012_leakage.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# no_of_inputs = 3  # Number of inputs in the circuit\n",
    "# rows_for_leakage=df_samples[max(0,num_rows-1)//(2**no_of_inputs):]\n",
    "\n",
    "# generate_leakage('A012/45nm_MGK.pm', 'A012/A012_leakage.net', no_of_inputs, 'A012/A012_leakage.csv',parameters,[2,1],rows_for_leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. A022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'A022'\n",
    "# file_name = 'A022_leakage.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# no_of_inputs = 4  # Number of inputs in the circuit\n",
    "# rows_for_leakage=df_samples[max(0,num_rows-1)//(2**no_of_inputs):]\n",
    "\n",
    "# generate_leakage('A022/45nm_MGK.pm', 'A022/A022_leakage.net', no_of_inputs, 'A022/A022_leakage.csv',parameters,[2,1],rows_for_leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. A031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'A031'\n",
    "# file_name = 'A031_leakage.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# no_of_inputs = 4  # Number of inputs in the circuit\n",
    "# rows_for_leakage=df_samples[max(0,num_rows-1)//(2**no_of_inputs):]\n",
    "\n",
    "# generate_leakage('A031/45nm_MGK.pm', 'A031/A031_leakage.net', no_of_inputs, 'A031/A031_leakage.csv',parameters,[4,3],rows_for_leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. A0112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'A0112'\n",
    "# file_name = 'A0112_leakage.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# no_of_inputs = 4  # Number of inputs in the circuit\n",
    "# rows_for_leakage=df_samples[max(0,num_rows-1)//(2**no_of_inputs):]\n",
    "\n",
    "# generate_leakage('A0112/45nm_MGK.pm', 'A0112/A0112_leakage.net', no_of_inputs, 'A0112/A0112_leakage.csv',parameters,[3,1],rows_for_leakage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
