{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv\n",
    "import subprocess\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generating files for delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Function to extract parameter values from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract parameter value from content\n",
    "def extract_parameter_value(file_content, parameter):\n",
    "    matches = re.findall(rf'\\b{parameter}\\s*=\\s*([\\d.e+-]+)', file_content)\n",
    "    if matches:\n",
    "        return matches[0], float(matches[1])  # Return the second occurrence\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Function to calculate mean and standard deviation for parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(file_path, parameter):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    _, mean = extract_parameter_value(content, parameter)\n",
    "    std = mean / 30  # Assuming a standard deviation of 1/30th of the mean\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Function to modify files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def modify_file(file_path, temp, supply, cqload, lmin, wmin, whichBlock, no_of_inputs):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.read()\n",
    "        lines = file.readlines()\n",
    "\n",
    "    data = re.sub(r'^dc TEMP .+$', f'dc TEMP {temp:.2f} {temp:.2f} {85}', data, flags=re.MULTILINE)\n",
    "    data = re.sub(r'^\\.PARAM SUPPLY=.+$', f'.PARAM SUPPLY={supply:.2f}', data, flags=re.MULTILINE)\n",
    "    data = re.sub(r'Cqload Vout gnd .+f', f'Cqload Vout gnd {cqload:.2f}f', data)\n",
    "    data = re.sub(r'\\.PARAM Lmin=.+$', f'.PARAM Lmin={lmin:.2f}n', data, flags=re.MULTILINE)\n",
    "    data = re.sub(r'\\.PARAM Wmin=.+$', f'.PARAM Wmin={wmin:.2f}n', data, flags=re.MULTILINE)\n",
    "    \n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    curBlock_Vin, curBlock_meas = 0, 0\n",
    "    cnt_Vin, cnt_meas = no_of_inputs, 2\n",
    "    for i in range(len(lines)):\n",
    "        if lines[i].startswith('*Vin1'):\n",
    "            curBlock_Vin += 1\n",
    "        \n",
    "        if curBlock_Vin == whichBlock and cnt_Vin >= 1:\n",
    "            if lines[i].startswith('*Vin1') or lines[i].startswith('*Vin2') or lines[i].startswith('*Vin3') or lines[i].startswith('*Vin4'):\n",
    "                lines[i] = lines[i][1:]\n",
    "                cnt_Vin -= 1\n",
    "        \n",
    "        if curBlock_meas // 2 == whichBlock - 1 and cnt_meas >= 1:\n",
    "            if lines[i].startswith('*.measure'):\n",
    "                lines[i] = lines[i][1:]\n",
    "                cnt_meas -= 1\n",
    "        \n",
    "        if lines[i].startswith('*.measure'):\n",
    "            curBlock_meas += 1\n",
    "    \n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 Function to modify leakage files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def modify_file_leakage(file_path, temp, supply, lmin, wmin, *Vin_values):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.read()\n",
    "        lines = file.readlines()\n",
    "\n",
    "    data = re.sub(r'^dc TEMP .+$', f'dc TEMP {temp:.2f} {temp:.2f} {85}', data, flags=re.MULTILINE)\n",
    "    data = re.sub(r'^\\.PARAM SUPPLY=.+$', f'.PARAM SUPPLY={supply:.2f}', data, flags=re.MULTILINE)\n",
    "    data = re.sub(r'\\.PARAM Lmin=.+$', f'.PARAM Lmin={lmin:.2f}n', data, flags=re.MULTILINE)\n",
    "    data = re.sub(r'\\.PARAM Wmin=.+$', f'.PARAM Wmin={wmin:.2f}n', data, flags=re.MULTILINE)\n",
    "    \n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    \n",
    "    j,modified=0,0\n",
    "    for i in range(len(lines)):\n",
    "        if modified==len(Vin_values):\n",
    "            break\n",
    "        if lines[i].startswith(f'Vin{j+1}'):\n",
    "            parts = lines[i].split()\n",
    "            parts[-1] = str(Vin_values[j])\n",
    "            lines[i] = ' '.join(parts) + '\\n'\n",
    "            j += 1\n",
    "            modified += 1\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.writelines(lines)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.6 Function to run ngspice commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import re\n",
    "\n",
    "def run_ngspice(file_path):\n",
    "    output = subprocess.check_output(['ngspice', '-b', file_path]).decode('utf-8')\n",
    "    delay_lh_match = re.search(r'delay_lh\\s*=\\s*([\\d.e+-]+)', output)\n",
    "    delay_hl_match = re.search(r'delay_hl\\s*=\\s*([\\d.e+-]+)', output)\n",
    "    delay_lh = float(delay_lh_match.group(1)) if delay_lh_match else None\n",
    "    delay_hl = float(delay_hl_match.group(1)) if delay_hl_match else None\n",
    "    \n",
    "    return delay_lh, delay_hl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.7 Function to calculate delay for a file and save it as csv file\n",
    "\n",
    "Inputs:\n",
    "1. PTM file (.pm)\n",
    "2. Circuit Netlist (.net)\n",
    "3. Number of samples to generate\n",
    "4. CSV file path\n",
    "\n",
    "Output:\n",
    "1. Modified CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_delay(parameters, ptm_file, netlist_file, csv_file, no_of_inputs, df_samples):\n",
    "    \n",
    "    # Load file content\n",
    "    with open(ptm_file, 'r') as file:\n",
    "        original_content = file.read()\n",
    "        \n",
    "    with open(netlist_file, 'r') as file:\n",
    "        original_content_net = file.read()\n",
    "        \n",
    "    # Make a copy of the original content for modification\n",
    "    modified_content = original_content\n",
    "\n",
    "    # Replace parameter values in the original file with sampled values\n",
    "    with open(csv_file, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        header_row = ['TEMP', 'pvdd', 'Cqload','Lmin', 'Wmin', 'toxe_n', 'toxm_n', 'toxref_n', 'toxp_n', 'xj_n', 'ndep_n','toxe_p', 'toxm_p', 'toxref_p', 'toxp_p', 'xj_p', 'ndep_p']\n",
    "        for node in range(no_of_inputs):\n",
    "            header_row += [f'delay_node{chr(97 + node)}']\n",
    "        num_rows = sum(1 for _ in open(csv_file, 'r'))\n",
    "        if num_rows==0:\n",
    "            writer.writerow(header_row)\n",
    "            \n",
    "        try: \n",
    "            for i in range(len(df_samples)):\n",
    "                i+=max(0,num_rows-1)\n",
    "                row = []\n",
    "                \n",
    "                # Extracting samples from DataFrame\n",
    "                lmin = df_samples['lmin'][i]\n",
    "                wmin = df_samples['wmin'][i]\n",
    "                temp = df_samples['temp'][i]\n",
    "                supply = df_samples['supply'][i]\n",
    "                cqload = df_samples['cqload'][i]\n",
    "                \n",
    "                # Replace parameter values in the original file with sampled values\n",
    "                for param in parameters:\n",
    "                    nmos_value=df_samples[param+'_n'][i]\n",
    "                    pmos_value=df_samples[param+'_p'][i]\n",
    "                    modified_content = re.sub(rf'\\b{param}\\s*=\\s*([\\d.e+-]+)', f'{param} = {pmos_value:.6e}', modified_content, count=2)\n",
    "                    modified_content = re.sub(rf'\\b{param}\\s*=\\s*([\\d.e+-]+)', f'{param} = {nmos_value:.6e}', modified_content, count=1)   \n",
    "                with open(ptm_file, 'w') as file:\n",
    "                    file.write(modified_content)\n",
    "                    \n",
    "                delay_values = []\n",
    "                for node in range(no_of_inputs):\n",
    "                    modify_file(netlist_file, temp, supply, cqload, lmin, wmin, node+1, no_of_inputs)\n",
    "                    \n",
    "                    delay_lh, delay_hl = run_ngspice(netlist_file)\n",
    "                    \n",
    "                    with open(netlist_file, 'w') as file:\n",
    "                        file.write(original_content_net)\n",
    "                    \n",
    "                    delay_values.append((delay_hl+delay_lh)/2)\n",
    "                \n",
    "                row.extend([temp, supply, cqload, lmin * 1e-9, wmin * 1e-9])\n",
    "                row.extend([df_samples[param+'_n'][i] for param in parameters])\n",
    "                row.extend([df_samples[param+'_p'][i] for param in parameters])\n",
    "                row.extend(delay_values)\n",
    "                writer.writerow(row)\n",
    "    \n",
    "        finally:\n",
    "            # Restore original content of ptm_file and netlist_file\n",
    "            with open(ptm_file, 'w') as file:\n",
    "                file.write(original_content)\n",
    "                \n",
    "            with open(netlist_file, 'w') as file:\n",
    "                file.write(original_content_net)\n",
    "\n",
    "            print(f\"Samples generated and saved in {csv_file}. Original files restored.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Defining Parameters to search for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters from file\n",
    "parameters = [\n",
    "    'toxe', 'toxm', 'toxref','toxp', 'xj', 'ndep'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samples=pd.read_csv('samples_22nm_MGK.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Generating Delay matrices for all files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Gates essential for C499 Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. INVERTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples generated and saved in INVERTER/INVERTER_delay.csv. Original files restored.\n"
     ]
    }
   ],
   "source": [
    "directory = 'INVERTER'\n",
    "file_name = 'INVERTER_delay.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "generate_delay(parameters,'INVERTER/22nm_MGK.pm', 'INVERTER/INVERTER.net', 'INVERTER/INVERTER_delay.csv',1,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. AND_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples generated and saved in AND/AND_2_delay.csv. Original files restored.\n"
     ]
    }
   ],
   "source": [
    "directory = 'AND'\n",
    "file_name = 'AND_2_delay.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "generate_delay(parameters,'AND/22nm_MGK.pm', 'AND/AND.net', 'AND/AND_2_delay.csv',2,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. AND_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples generated and saved in AND_3/AND_3_delay.csv. Original files restored.\n"
     ]
    }
   ],
   "source": [
    "directory = 'AND_3'\n",
    "file_name = 'AND_3_delay.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "generate_delay(parameters,'AND_3/22nm_MGK.pm', 'AND_3/AND.net', 'AND_3/AND_3_delay.csv',3,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'XOR'\n",
    "file_name = 'XOR_delay.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "generate_delay(parameters,'XOR/22nm_MGK.pm', 'XOR/XOR.net', 'XOR/XOR_delay.csv',2,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. OR2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'OR'\n",
    "file_name = 'OR_2_delay.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "generate_delay(parameters,'OR/22nm_MGK.pm', 'OR/OR.net', 'OR/OR_2_delay.csv',2,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Gates non-essential for C499 Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. NAND_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'NAND'\n",
    "# file_name = 'NAND_2_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'NAND/22nm_MGK.pm', 'NAND/NAND.net', 'NAND/NAND_2_delay.csv',2,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. NAND_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'NAND_3'\n",
    "# file_name = 'NAND_3_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'NAND_3/22nm_MGK.pm', 'NAND_3/NAND.net', 'NAND_3/NAND_3_delay.csv',3,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. NAND_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'NAND_4'\n",
    "# file_name = 'NAND_4_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'NAND_4/22nm_MGK.pm', 'NAND_4/NAND.net', 'NAND_4/NAND_4_delay.csv',4,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. NOR_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'NOR'\n",
    "# file_name = 'NOR_2_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'NOR/22nm_MGK.pm', 'NOR/NOR.net', 'NOR/NOR_2_delay.csv',2,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. NOR_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'NOR_3'\n",
    "# file_name = 'NOR_3_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'NOR_3/22nm_MGK.pm', 'NOR_3/NOR.net', 'NOR_3/NOR_3_delay.csv',3,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. NOR_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'NOR_4'\n",
    "# file_name = 'NOR_4_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'NOR_4/22nm_MGK.pm', 'NOR_4/NOR.net', 'NOR_4/NOR_4_delay.csv',4,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. AND_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'AND_4'\n",
    "# file_name = 'AND_4_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'AND_4/22nm_MGK.pm', 'AND_4/AND.net', 'AND_4/AND_4_delay.csv',4,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. A012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'A012'\n",
    "# file_name = 'A012_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'A012/22nm_MGK.pm', 'A012/A012.net', 'A012/A012_delay.csv',3,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. A022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'A022'\n",
    "# file_name = 'A022_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'A022/22nm_MGK.pm', 'A022/A022.net', 'A022/A022_delay.csv',4,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. A031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'A031'\n",
    "# file_name = 'A031_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'A031/22nm_MGK.pm', 'A031/A031.net', 'A031/A031_delay.csv',4,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. A0112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'A0112'\n",
    "# file_name = 'A0112_delay.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_delay=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# generate_delay(parameters,'A0112/22nm_MGK.pm', 'A0112/A0112.net', 'A0112/A0112_delay.csv',4,rows_for_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generating files for leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Generic numeric functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def round_to_nearest(value, values_list):\n",
    "    return min(values_list, key=lambda x: abs(x - value))\n",
    "\n",
    "def round_gate_voltage(value):\n",
    "    if value < 0.55:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Function to extract voltage and current data from a SPICE simulation output file.\n",
    "\n",
    "**Inputs:**\n",
    "1. `filename`: The filename of the SPICE simulation output file.\n",
    "2. `ratio_list`: A list containing two values representing the W/L ratio for PMOS and NMOS transistors respectively.\n",
    "\n",
    "**Output:**\n",
    "1. `df`: A pandas DataFrame containing the extracted data with the following columns:\n",
    "    - `MOSFET Type`: Type of the MOSFET (either 'PMOS' or 'NMOS').\n",
    "    - `W_L Ratio`: W/L ratio of the MOSFET.\n",
    "    - `Drain Voltage`: Voltage at the drain terminal of the MOSFET.\n",
    "    - `Gate Voltage`: Voltage at the gate terminal of the MOSFET.\n",
    "    - `Source Voltage`: Voltage at the source terminal of the MOSFET.\n",
    "    - `Drain Current`: Current flowing through the drain terminal of the MOSFET.\n",
    "    - `Gate Current`: Current flowing through the gate terminal of the MOSFET.\n",
    "    - `Source Current`: Current flowing through the source terminal of the MOSFET.\n",
    "    - `Body Current`: Body current of the MOSFET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_spice_data(filename, ratio_list):\n",
    "    text = os.popen(f\"ngspice {filename}\").read()\n",
    "    voltage_pattern = re.compile(r\"v\\((\\w+)\\) = ([\\d\\.\\-\\+e]+)\")\n",
    "    current_pattern = re.compile(r\"i\\((\\w+)\\) = ([\\d\\.\\-\\+e]+)\")\n",
    "\n",
    "    voltages = []\n",
    "    currents = []\n",
    "\n",
    "    for match in re.finditer(voltage_pattern, text):\n",
    "        voltages.append((match.group(1), float(match.group(2))))\n",
    "\n",
    "    for match in re.finditer(current_pattern, text):\n",
    "        currents.append((match.group(1), float(match.group(2))))\n",
    "\n",
    "    rows = []\n",
    "    \n",
    "    round_values = [i/20 for i in range(0, 23)]\n",
    "\n",
    "    # Determine MOSFET type based on the number of rows in the DataFrame\n",
    "    mosfet_type_list = ['PMOS'] * (len(voltages) // 6) + ['NMOS'] * (len(voltages) // 6)\n",
    "    # Calculate W_L ratio for PMOS and NMOS\n",
    "    pmos_ratio, nmos_ratio = ratio_list\n",
    "\n",
    "    for i in range(len(voltages) // 3):  # Assuming each MOSFET has 3 voltage values\n",
    "        index = i * 3\n",
    "        index_current = i * 4\n",
    "        mosfet_type = mosfet_type_list[i]\n",
    "        ratio = pmos_ratio if mosfet_type == 'PMOS' else nmos_ratio\n",
    "        rows.append({'MOSFET Type': mosfet_type,\n",
    "                     'W_L Ratio': ratio,\n",
    "                     'Drain Voltage': round_to_nearest(voltages[index][1], round_values),\n",
    "                     'Gate Voltage': round_gate_voltage(voltages[index+1][1]), # Assuming gate voltage is constant for all transistors\n",
    "                     'Source Voltage': round_to_nearest(voltages[index+2][1], round_values),\n",
    "                     'Drain Current': currents[index_current][1],\n",
    "                     'Gate Current': currents[index_current+1][1], # Assuming gate current is constant for all transistors\n",
    "                     'Source Current': currents[index_current+2][1],\n",
    "                     'Body Current': currents[index_current+3][1]})\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=['MOSFET Type', 'W_L Ratio', 'Drain Voltage', 'Gate Voltage', 'Source Voltage',\n",
    "                                     'Drain Current', 'Gate Current', 'Source Current', 'Body Current'])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Function to calculate the total leakage current of a MOSFET based on the true current values, terminal voltages, MOSFET type, and supply voltage.\n",
    "\n",
    "**Inputs:**\n",
    "1. `true_values`: A tuple containing the true values of drain current, gate current, source current, and body current.\n",
    "2. `drain_voltage`: Voltage at the drain terminal.\n",
    "3. `gate_voltage`: Voltage at the gate terminal.\n",
    "4. `source_voltage`: Voltage at the source terminal.\n",
    "5. `mos_type`: Type of the MOSFET ('PMOS' or 'NMOS').\n",
    "6. `supply`: Supply voltage.\n",
    "\n",
    "**Output:**\n",
    "1. `leakage_current`: The calculated total leakage current of the MOSFET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_leakage(true_values, drain_voltage, gate_voltage, source_voltage, mos_type,supply):\n",
    "    # Extracting true currents\n",
    "    true_drain_current, true_gate_current, true_source_current, true_body_current = true_values\n",
    "    \n",
    "    # Checking if the magnitudes of incoming currents match\n",
    "    \n",
    "    if mos_type == 'PMOS':\n",
    "        body_voltage=supply\n",
    "    else:\n",
    "        body_voltage=0   \n",
    "    \n",
    "    # Calculating outgoing currents based on terminal voltages and direction of current flow\n",
    "    incoming_currents = []\n",
    "    if mos_type == 'PMOS':\n",
    "        # For PMOS, drain is at a lower potential than gate or source\n",
    "        if (drain_voltage < source_voltage or drain_voltage < body_voltage) and true_drain_current < 0:\n",
    "            incoming_currents.append(abs(true_drain_current))\n",
    "        if (gate_voltage < source_voltage or gate_voltage < drain_voltage) and true_gate_current < 0:\n",
    "            incoming_currents.append(abs(true_gate_current))\n",
    "        if (source_voltage < drain_voltage or source_voltage < gate_voltage) and true_source_current < 0:\n",
    "            incoming_currents.append(abs(true_source_current))\n",
    "        if true_body_current < 0:\n",
    "            incoming_currents.append(abs(true_body_current))  # Body current always flows out\n",
    "    elif mos_type == 'NMOS':\n",
    "        # For NMOS, drain is at a higher potential than gate or source\n",
    "        if (drain_voltage > source_voltage or drain_voltage > gate_voltage) and true_drain_current < 0:\n",
    "            incoming_currents.append(abs(true_drain_current))\n",
    "        if (gate_voltage > source_voltage or gate_voltage > drain_voltage) and true_gate_current < 0:\n",
    "            incoming_currents.append(abs(true_gate_current))\n",
    "        if (source_voltage > drain_voltage or source_voltage > gate_voltage) and true_source_current < 0:\n",
    "            incoming_currents.append(abs(true_source_current))\n",
    "        if true_body_current < 0:\n",
    "            incoming_currents.append(abs(true_body_current))  # Body current always flows out\n",
    "    \n",
    "    # Calculating leakage current as the sum of outgoing currents\n",
    "    leakage_current = sum(incoming_currents)\n",
    "    return leakage_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def get_c499_true_leakage(filename):\n",
    "    text = os.popen(f\"ngspice {filename}\").read()\n",
    "    voltage_pattern = re.compile(r\"v\\((\\w+)\\) = ([\\d\\.\\-\\+e]+)\")\n",
    "    current_pattern = re.compile(r\"i\\((\\w+)\\) = ([\\d\\.\\-\\+e]+)\")\n",
    "\n",
    "    voltages = []\n",
    "    currents = []\n",
    "\n",
    "    for match in re.finditer(voltage_pattern, text):\n",
    "        voltages.append((match.group(1), float(match.group(2))))\n",
    "\n",
    "    for match in re.finditer(current_pattern, text):\n",
    "        currents.append((match.group(1), float(match.group(2))))\n",
    "\n",
    "    leakage=0\n",
    "    \n",
    "    for v,i in zip(voltages,currents):\n",
    "        leakage+=v[1]*i[1]\n",
    "    \n",
    "    return leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 Function to calculate the total leakage current for all rows in an original list of MOSFET data.\n",
    "\n",
    "**Inputs:**\n",
    "1. `original_list`: A list containing MOSFET data where each item is a list with the following format:\n",
    "    - `original_list[i][0]`: MOSFET type ('PMOS' or 'NMOS').\n",
    "    - `original_list[i][2]`: Drain voltage.\n",
    "    - `original_list[i][3]`: Gate voltage.\n",
    "    - `original_list[i][4]`: Source voltage.\n",
    "    - `original_list[i][5:9]`: True current values (drain current, gate current, source current, body current).\n",
    "2. `supply`: Supply voltage.\n",
    "\n",
    "**Output:**\n",
    "1. `total_leakage_current`: The sum of all calculated leakage currents for each row in the original list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_leakage_for_all_rows(original_list,supply):\n",
    "    all_leakage_currents = []\n",
    "    for i in range(len(original_list)):\n",
    "        leakage_current = calculate_leakage(original_list[i][5:9],\n",
    "                                            original_list[i][2],\n",
    "                                            original_list[i][3],\n",
    "                                            original_list[i][4],\n",
    "                                            original_list[i][0],supply)\n",
    "        all_leakage_currents.append(leakage_current)\n",
    "        \n",
    "    return sum(all_leakage_currents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.6 Function to generate leakage values and save it in a csv file\n",
    "\n",
    "Inputs:\n",
    "1. PTM file (.pm)\n",
    "2. Circuit Netlist (.net)\n",
    "3. Number of inputs in the circuit\n",
    "4. Number of samples to generate\n",
    "5. CSV file path\n",
    "6. Parameters\n",
    "\n",
    "Output:\n",
    "1. Modified CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "from itertools import product\n",
    "\n",
    "def generate_leakage(PM_file, netlist_file, no_of_inputs, csv_file_path, parameters, file_ratio, df_samples,isC499=False):\n",
    "    # Load file content\n",
    "    with open(PM_file, 'r') as file:\n",
    "        original_content = file.read()\n",
    "\n",
    "    with open(netlist_file, 'r') as file:\n",
    "        original_content_leakage = file.read()\n",
    "\n",
    "    # Make a copy of the original content for modification\n",
    "    modified_content = original_content\n",
    "\n",
    "    # Replace parameter values in the original file with sampled values\n",
    "    with open(csv_file_path, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        header_row = ['Vin_' + chr(65 + i) for i in range(no_of_inputs)] + ['TEMP', 'pvdd', 'Lmin', 'Wmin', 'toxe_n', 'toxm_n', 'toxref_n', 'toxp_n', 'xj_n', 'ndep_n','toxe_p', 'toxm_p', 'toxref_p', 'toxp_p', 'xj_p', 'ndep_p'] + ['Leakage_power']\n",
    "        num_rows = sum(1 for _ in open(csv_file_path, 'r'))\n",
    "        to_skip=(num_rows%(2**no_of_inputs))-1;\n",
    "        to_skip=(to_skip+(2**no_of_inputs))%2**no_of_inputs\n",
    "        if num_rows==0:\n",
    "            writer.writerow(header_row)\n",
    "            to_skip=0\n",
    "        skipped=0\n",
    "        try:\n",
    "            for i in range(len(df_samples)):\n",
    "                i+=max(0,num_rows-1)//2**(no_of_inputs)\n",
    "                lmin = df_samples['lmin'][i]\n",
    "                wmin = df_samples['wmin'][i]\n",
    "                temp = df_samples['temp'][i]\n",
    "                supply = df_samples['supply'][i]\n",
    "\n",
    "                # Replace parameter values in the original file with sampled values\n",
    "                for param in parameters:\n",
    "                    nmos_value=df_samples[param+'_n'][i]\n",
    "                    pmos_value=df_samples[param+'_p'][i]\n",
    "                    modified_content = re.sub(rf'\\b{param}\\s*=\\s*([\\d.e+-]+)', f'{param} = {pmos_value:.6e}', modified_content, count=2)\n",
    "                    modified_content = re.sub(rf'\\b{param}\\s*=\\s*([\\d.e+-]+)', f'{param} = {nmos_value:.6e}', modified_content, count=1)   \n",
    "                \n",
    "                # Save modified content back to the original file\n",
    "                with open(PM_file, 'w') as file:\n",
    "                    file.write(modified_content)\n",
    "                \n",
    "                \n",
    "\n",
    "                # Iterate over all possible combinations of input voltages\n",
    "                for Vin_values in product(range(2), repeat=no_of_inputs):\n",
    "                    if skipped<to_skip:\n",
    "                        skipped+=1\n",
    "                        continue\n",
    "                    input_values = [(supply if val == 1 else 0) for val in Vin_values]\n",
    "                    modify_file_leakage(netlist_file, temp, supply, lmin, wmin, *input_values)\n",
    "                    \n",
    "                    # Extracting voltage and current values from executing netlist\n",
    "                    if isC499==False:\n",
    "                        file_df_extracted = extract_spice_data(netlist_file, file_ratio)\n",
    "                        leakage_currents = calculate_leakage_for_all_rows(file_df_extracted.values.tolist(), supply)\n",
    "                        row = list(Vin_values) + [temp, supply, lmin * 1e-9, wmin * 1e-9] + [df_samples[param+'_n'][i] for param in parameters]+[df_samples[param+'_p'][i] for param in parameters] + [leakage_currents * (supply + sum(Vin_values))]\n",
    "                        writer.writerow(row)\n",
    "                    \n",
    "                    else:\n",
    "                        leakage_power=get_c499_true_leakage(netlist_file)\n",
    "                        row = list(Vin_values) + [temp, supply, lmin * 1e-9, wmin * 1e-9] + [df_samples[param+'_n'][i] for param in parameters]+[df_samples[param+'_p'][i] for param in parameters] + [abs(leakage_power)]\n",
    "                        writer.writerow(row)\n",
    "                        \n",
    "                    \n",
    "        finally:\n",
    "\n",
    "            # Revert changes back to original values\n",
    "            with open(PM_file, 'w') as file:\n",
    "                file.write(original_content)\n",
    "\n",
    "            with open(netlist_file, 'w') as file:\n",
    "                file.write(original_content_leakage)\n",
    "\n",
    "            print(f\"Samples generated and saved in '{csv_file_path}'. Original files restored.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.7 Function for and gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import product\n",
    "\n",
    "def calculate_and_or_gate_leakage(nand_file_path, inverter_file_path, output_file_path, no_of_inputs):\n",
    "    # Read the input CSV files\n",
    "    nand_df = pd.read_csv(nand_file_path)\n",
    "    inverter_df = pd.read_csv(inverter_file_path)\n",
    "\n",
    "    # Define the keys for the resulting DataFrame\n",
    "    nand_parameter_key = [f'Vin_{chr(65+i)}' for i in range(no_of_inputs)] + ['TEMP', 'pvdd', 'Lmin', 'Wmin', 'toxe_n', 'toxm_n', 'toxref_n', 'toxp_n', 'xj_n', 'ndep_n', 'toxe_p', 'toxm_p', 'toxref_p', 'toxp_p', 'xj_p', 'ndep_p']\n",
    "    and_df = pd.DataFrame({key: [] for key in nand_parameter_key + ['Leakage_power']})\n",
    "\n",
    "    # Define the key for leakage power\n",
    "    leakage_key = 'Leakage_power'\n",
    "\n",
    "    # Iterate over the rows of NAND_df\n",
    "    cur_pointer=0\n",
    "    for index, nand_row in nand_df.iterrows():\n",
    "        # Get the corresponding inverter input for the current NAND input combination\n",
    "        input_combination = nand_row[[f'Vin_{chr(65+i)}' for i in range(no_of_inputs)]].tolist()\n",
    "        inverter_input = 0 if all(bit == 1 for bit in input_combination) else 1\n",
    "        \n",
    "        \n",
    "        # Sum the leakage power of the NAND gate and the matching inverter\n",
    "        row_no=cur_pointer+(inverter_input==1)\n",
    "        total_leakage_power = nand_row[leakage_key] + inverter_df.loc[row_no,leakage_key]\n",
    "\n",
    "        # Append the values to the DataFrame\n",
    "        and_df = pd.concat([and_df, pd.DataFrame({**dict(nand_row), leakage_key: total_leakage_power}, index=[0])], ignore_index=True)\n",
    "        \n",
    "        if (index+1)%((2**no_of_inputs))==0:\n",
    "            cur_pointer += 2\n",
    "        \n",
    "\n",
    "    # Save the resulting DataFrame to a CSV file\n",
    "    and_df.to_csv(output_file_path, index=False)\n",
    "    \n",
    "    print(f\"Samples generated and saved in '{output_file_path}'. Original files restored.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Defining Parameters to search for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List of parameters to search for\n",
    "parameters = [\n",
    "    'toxe', 'toxm', 'toxref','toxp', 'xj', 'ndep'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Generating Leakage matrices for all files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Gates essential for C499 Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. INVERTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'INVERTER'\n",
    "file_name = 'INVERTER_leakage.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "no_of_inputs = 1  # Number of inputs in the circuit\n",
    "rows_for_leakage=df_samples[max(0,num_rows-1)//2**(no_of_inputs):]\n",
    "generate_leakage('INVERTER/22nm_MGK.pm', 'INVERTER/INVERTER_leakage.net', no_of_inputs, 'INVERTER/INVERTER_leakage.csv',parameters,[2,1],rows_for_leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. NAND_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'NAND'\n",
    "file_name = 'NAND_2_leakage.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "no_of_inputs = 2  # Number of inputs in the circuit\n",
    "rows_for_leakage=df_samples[max(0,num_rows-1)//2**(no_of_inputs):]\n",
    "generate_leakage('NAND/22nm_MGK.pm', 'NAND/NAND_leakage.net', no_of_inputs, 'NAND/NAND_2_leakage.csv', parameters, [2,2],rows_for_leakage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. NAND_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'NAND_3'\n",
    "file_name = 'NAND_3_leakage.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "no_of_inputs = 3  # Number of inputs in the circuit\n",
    "rows_for_leakage=df_samples[max(0,num_rows-1)//2**(no_of_inputs):]\n",
    "\n",
    "generate_leakage('NAND_3/22nm_MGK.pm', 'NAND_3/NAND_leakage.net', no_of_inputs, 'NAND_3/NAND_3_leakage.csv',parameters,[2,3],rows_for_leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. NOR_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'NOR'\n",
    "file_name = 'NOR_2_leakage.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "no_of_inputs = 2  # Number of inputs in the circuit\n",
    "rows_for_leakage=df_samples[max(0,num_rows-1)//2**(no_of_inputs):]\n",
    "\n",
    "# NOR_2\n",
    "generate_leakage('NOR/22nm_MGK.pm', 'NOR/NOR_leakage.net', no_of_inputs, 'NOR/NOR_2_leakage.csv', parameters, [4, 1],rows_for_leakage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'XOR'\n",
    "file_name = 'XOR_leakage.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "no_of_inputs = 2  # Number of inputs in the circuit\n",
    "rows_for_leakage=df_samples[max(0,num_rows-1)//2**(no_of_inputs):]\n",
    "\n",
    "generate_leakage('XOR/22nm_MGK.pm', 'XOR/XOR_leakage.net', no_of_inputs, 'XOR/XOR_leakage.csv',parameters,[2,1],rows_for_leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. AND_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For AND2\n",
    "calculate_and_or_gate_leakage('NAND/NAND_2_leakage.csv', 'INVERTER/INVERTER_leakage.csv', 'AND/AND_2_leakage.csv',2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. AND_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For AND3\n",
    "calculate_and_or_gate_leakage('NAND_3/NAND_3_leakage.csv', 'INVERTER/INVERTER_leakage.csv', 'AND_3/AND_3_leakage.csv',3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. OR_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_and_or_gate_leakage('NOR/NOR_2_leakage.csv', 'INVERTER/INVERTER_leakage.csv', 'OR/OR_2_leakage.csv',2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. C499"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'C499'\n",
    "file_name = 'C499_true_leakage.csv'\n",
    "file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(file_path):\n",
    "    # Write some data to the file\n",
    "    data = \"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "# Open the CSV file and count the rows\n",
    "num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "no_of_inputs = 1  # Number of inputs in the circuit\n",
    "rows_for_leakage=df_samples[max(0,num_rows-1)//2**(no_of_inputs):]\n",
    "\n",
    "generate_leakage('C499/22nm_MGK.pm', 'C499/C499_true_leakage.net', no_of_inputs, 'C499/C499_true_leakage.csv',parameters,[2,1],rows_for_leakage,isC499=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Gates non-essential for C499 Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. NAND_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'NAND_4'\n",
    "# file_name = 'NAND_4_leakage.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# no_of_inputs = 4  # Number of inputs in the circuit\n",
    "# rows_for_leakage=df_samples[max(0,num_rows-1)//2**(no_of_inputs):]\n",
    "\n",
    "# generate_leakage('NAND_4/22nm_MGK.pm', 'NAND_4/NAND_leakage.net', no_of_inputs, 'NAND_4/NAND_4_leakage.csv',parameters,[2,4],rows_for_leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. AND_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For AND4\n",
    "# calculate_and_or_gate_leakage('NAND_4/NAND_4_leakage.csv', 'INVERTER/INVERTER_leakage.csv', 'AND_4/AND_4_leakage.csv',4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. NOR_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'NOR_3'\n",
    "# file_name = 'NOR_3_leakage.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# no_of_inputs = 3  # Number of inputs in the circuit\n",
    "# rows_for_leakage=df_samples[max(0,num_rows-1)//2**(no_of_inputs):]\n",
    "\n",
    "# generate_leakage('NOR_3/22nm_MGK.pm', 'NOR_3/NOR_leakage.net', no_of_inputs, 'NOR_3/NOR_3_leakage.csv', parameters, [6, 1],rows_for_leakage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. NOR_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'NOR_4'\n",
    "# file_name = 'NOR_4_leakage.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# rows_for_leakage=df_samples[max(0,num_rows-1):]\n",
    "\n",
    "# no_of_inputs = 4  # Number of inputs in the circuit\n",
    "# generate_leakage('NOR_4/22nm_MGK.pm', 'NOR_4/NOR_leakage.net', no_of_inputs, 'NOR_4/NOR_4_leakage.csv',parameters,[8,1],rows_for_leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. A012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'A012'\n",
    "# file_name = 'A012_leakage.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# no_of_inputs = 3  # Number of inputs in the circuit\n",
    "# rows_for_leakage=df_samples[max(0,num_rows-1)//2**(no_of_inputs):]\n",
    "\n",
    "# generate_leakage('A012/22nm_MGK.pm', 'A012/A012_leakage.net', no_of_inputs, 'A012/A012_leakage.csv',parameters,[2,1],rows_for_leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. A022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'A022'\n",
    "# file_name = 'A022_leakage.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# no_of_inputs = 4  # Number of inputs in the circuit\n",
    "# rows_for_leakage=df_samples[max(0,num_rows-1)//2**(no_of_inputs):]\n",
    "\n",
    "# generate_leakage('A022/22nm_MGK.pm', 'A022/A022_leakage.net', no_of_inputs, 'A022/A022_leakage.csv',parameters,[2,1],rows_for_leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. A031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'A031'\n",
    "# file_name = 'A031_leakage.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# no_of_inputs = 4  # Number of inputs in the circuit\n",
    "# rows_for_leakage=df_samples[max(0,num_rows-1)//2**(no_of_inputs):]\n",
    "\n",
    "# generate_leakage('A031/22nm_MGK.pm', 'A031/A031_leakage.net', no_of_inputs, 'A031/A031_leakage.csv',parameters,[4,3],rows_for_leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. A0112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory = 'A0112'\n",
    "# file_name = 'A0112_leakage.csv'\n",
    "# file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# # Check if the file already exists\n",
    "# if not os.path.exists(file_path):\n",
    "#     # Write some data to the file\n",
    "#     data = \"\"\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         file.write(data)\n",
    "\n",
    "# # Open the CSV file and count the rows\n",
    "# num_rows = sum(1 for _ in open(file_path, 'r'))\n",
    "# no_of_inputs = 4  # Number of inputs in the circuit\n",
    "# rows_for_leakage=df_samples[max(0,num_rows-1)//2**(no_of_inputs):]\n",
    "# generate_leakage('A0112/22nm_MGK.pm', 'A0112/A0112_leakage.net', no_of_inputs, 'A0112/A0112_leakage.csv',parameters,[3,1],rows_for_leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Cluster for Inverter using BIC score 4\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 7.350720553418678e-08\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 2.5607130207477183e-07\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 4.006084634653454e-08\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 3.8904436901020685e-08\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 6.191328149063748e-08\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 7.350720551929271e-08\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 2.802641240393817e-07\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 9.54511433525224e-07\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 1.3041888745427365e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 9.293341291291128e-08\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 2.3353207922109503e-07\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 2.8026412406534925e-07\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 2.632802933445523e-07\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 7.847674842549667e-07\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 1.363593724057606e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 1.3637899046992162e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 1.9353983926157894e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 2.6328029359802434e-07\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 2.802641240393817e-07\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 9.54511433525224e-07\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 1.3041888745427365e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 9.300523884888388e-08\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 2.3415320702533955e-07\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 2.8026412406534925e-07\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 5.103303074423867e-08\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 2.137077475128146e-07\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 2.8218754699690044e-08\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 2.809360834002429e-08\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 4.311833911905256e-08\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 5.103303078565538e-08\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 2.802641240393817e-07\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 9.54511433525224e-07\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 1.3041888745427365e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 9.287837098894827e-08\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 2.3191749560085602e-07\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 2.8026412406534925e-07\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 2.0415442943243413e-07\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 8.625672888334823e-07\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 1.1247437821482198e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 1.0698645052859747e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 1.5604127960044066e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 2.0415442934350808e-07\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 2.802641240393817e-07\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 9.54511433525224e-07\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 1.3041888745427365e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 9.312655488484653e-08\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 2.361860394745307e-07\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 2.8026412406534925e-07\n",
      "Optimal Cluster for Inverter using BIC score 5\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 2.9115639661314017e-05\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 5.220100750594563e-05\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 1.4294891790996374e-05\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 1.3765097248428055e-05\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 1.6981437784506894e-05\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 2.805034630195431e-05\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 0.00013855282923022977\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 0.00020273449554053508\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 8.170297799399754e-05\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 1.5647931105882155e-05\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 3.0616888022244205e-05\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 2.7672195709839694e-05\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 1.7270970640321818e-06\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 3.098094393928585e-06\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 7.436187773332192e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 7.59619320561663e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 1.0619963656679166e-06\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 1.727097064606008e-06\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 0.00013855282923022977\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 0.00020273449554053508\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 8.170297799399754e-05\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 1.5607483596954953e-05\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 3.062516086193195e-05\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 2.7672195709839694e-05\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 5.1973475447580894e-05\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 5.5483188128444874e-05\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 2.2359720428845304e-05\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 2.2576065930530934e-05\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 2.443261167226172e-05\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 4.557955191526763e-05\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 0.00013855282923022977\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 0.00020273449554053508\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 8.170297799399754e-05\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 1.5587680522765206e-05\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 3.072756411840083e-05\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 2.7672195709839694e-05\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 5.4611838261851164e-05\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 6.915033760137151e-05\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 2.311915948071923e-05\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 2.30354791667123e-05\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 2.6293178193835552e-05\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 4.3389557908362244e-05\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 0.00013855282923022977\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 0.00020273449554053508\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 8.170297799399754e-05\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 1.562078450054901e-05\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 3.12010342312481e-05\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 2.7672195709839694e-05\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 2.0235934594829414e-06\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 6.831755001988199e-06\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 9.515997116212481e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 9.633382089380156e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 1.665454143432188e-06\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 2.0235934597636727e-06\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 0.00013855282923022977\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 0.00020273449554053508\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 8.170297799399754e-05\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 1.5640254786686594e-05\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 3.044473486531597e-05\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 2.7672195709839694e-05\n",
      "Optimal Cluster for Inverter using BIC score 5\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 2.778776237588983e-07\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 8.402023087025943e-07\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 1.3097788708723675e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 1.316406664852775e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 2.2167262847135126e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 2.7787762381334317e-07\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 8.885322889564456e-07\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 3.318292698608485e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 4.6715304326074043e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 3.0021485395018694e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 7.750663881067051e-07\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 8.885322888509901e-07\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 9.019370902456012e-07\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 2.6552483042758044e-06\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 4.4170799923829e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 4.3451983044796637e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 6.915481913355552e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 9.01937090513088e-07\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 8.885322889564456e-07\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 3.318292698608485e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 4.6715304326074043e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 3.010099938701026e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 7.791166970382039e-07\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 8.885322888509901e-07\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 4.585414215686972e-07\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 1.064000867694722e-06\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 2.2590961501925388e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 2.325487842266347e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 3.3240704644712066e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 4.5854142116654515e-07\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 8.885322889564456e-07\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 3.318292698608485e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 4.6715304326074043e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 3.0064428894521244e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 7.85859108069269e-07\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 8.885322888509901e-07\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 4.3411661860650337e-07\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 1.4136755301377732e-06\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 2.292766088830789e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 2.23859728667007e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 3.665537701640245e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 4.341166183450988e-07\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 8.885322889564456e-07\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 3.318292698608485e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 4.6715304326074043e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 3.009442745434911e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 7.722193745220622e-07\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 8.885322888509901e-07\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 5.702250549526423e-07\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 1.911051762274093e-06\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 2.8469624424765696e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 2.7907395444653086e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 4.638208658328187e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 5.702250542118592e-07\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 8.885322889564456e-07\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 3.318292698608485e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 4.6715304326074043e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 3.0000028028846247e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 7.871947678230065e-07\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 8.885322888509901e-07\n",
      "Optimal Cluster for Inverter using BIC score 10\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 3.6592826360958377e-07\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 7.945770251113198e-07\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 1.743647261027366e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 1.7323243934617316e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 2.5189252903301356e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 3.65928263718049e-07\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 1.473338462443667e-06\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 7.103138988847091e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 9.060864188036853e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 3.8230228633070174e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 1.3718374068854329e-06\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 1.4733384622940737e-06\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 2.66240271861397e-07\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 4.5127915114316915e-07\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 1.3366369396938058e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 1.1178620486675713e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 1.23373395192559e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 2.6624027016737546e-07\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 1.473338462443667e-06\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 7.103138988847091e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 9.060864188036853e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 3.8161386280428147e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 1.3663958975041667e-06\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 1.4733384622940737e-06\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 5.421332735099691e-07\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 1.6841693713274897e-06\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 2.7160550841559094e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 2.723607731290531e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 4.543218753766123e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 5.421332736806051e-07\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 1.473338462443667e-06\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 7.103138988847091e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 9.060864188036853e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 3.8065655225075527e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 1.3725801255539924e-06\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 1.4733384622940737e-06\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 6.221982384246367e-07\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 1.6646194055989017e-06\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 3.0948190633240534e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 2.9875751030397093e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 4.709287169658553e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 6.221982388797811e-07\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 1.473338462443667e-06\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 7.103138988847091e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 9.060864188036853e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 3.8082262459837704e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 1.3791753289282271e-06\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 1.4733384622940737e-06\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 4.534098502970202e-08\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 4.272057719552572e-08\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 4.3193861125552856e-08\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 2.9612673572161545e-08\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 1.2322899139700467e-08\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 4.5340982985185546e-08\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 1.473338462443667e-06\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 7.103138988847091e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 9.060864188036853e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 3.8177140956052473e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 1.3641396139539347e-06\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 1.4733384622940737e-06\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 3.2872395071337854e-07\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 7.135427708433386e-07\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 1.5395917447338912e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 1.2393113721736098e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 2.1807202362221555e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 3.2872395054076063e-07\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 1.473338462443667e-06\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 7.103138988847091e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 9.060864188036853e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 3.814217411252686e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 1.3795917622601688e-06\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 1.4733384622940737e-06\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 3.211066731618581e-07\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 8.676300915849461e-07\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 1.5765694082424283e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 1.5599704956447944e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 2.4159654027445253e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 3.211066730065737e-07\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 1.473338462443667e-06\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 7.103138988847091e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 9.060864188036853e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 3.8152334864181085e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 1.363728098635045e-06\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 1.4733384622940737e-06\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 2.61447272295307e-07\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 9.346800039011841e-07\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 1.1463831802292728e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 1.0046941078084123e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 2.1725995814075727e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 2.6144727230285727e-07\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 1.473338462443667e-06\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 7.103138988847091e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 9.060864188036853e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 3.8168953436553133e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 1.3860557749431075e-06\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 1.4733384622940737e-06\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 1.754824526217271e-06\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 5.092458567095236e-06\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 8.591044730735026e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 8.553805103789437e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 1.323584358778452e-06\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 1.7548245260980542e-06\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 1.473338462443667e-06\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 7.103138988847091e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 9.060864188036853e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 3.814600867200689e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 1.3524168684961571e-06\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 1.4733384622940737e-06\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 8.204629151108561e-07\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 2.3578628317689893e-06\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 4.1353574199078475e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 4.071060868353483e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 6.300177278423236e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 8.204629152127716e-07\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 1.473338462443667e-06\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 7.103138988847091e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 9.060864188036853e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 3.8175327096364767e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 1.3800587342806237e-06\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 1.4733384622940737e-06\n",
      "Optimal Cluster for Inverter using BIC score 5\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 5.420252076797327e-07\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 1.891339550803579e-06\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 3.669621491421281e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 3.47911454728179e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 4.6443772400181376e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 5.420252078868349e-07\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 8.431973927300117e-07\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 4.390954281686234e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 4.349395061365779e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 4.0042545281233335e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 9.231982738643903e-07\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 8.43197392544123e-07\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 4.769649752470367e-07\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 8.705381270222381e-07\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 2.2966021525534202e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 2.2514382305635407e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 3.280467562122257e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 4.769649753735966e-07\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 8.431973927300117e-07\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 4.390954281686234e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 4.349395061365779e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 4.007439988590113e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 9.064026092939429e-07\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 8.43197392544123e-07\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 9.942846534020066e-07\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 2.3202060326762378e-06\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 4.825770198805022e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 4.933603756749894e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 6.943965070999892e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 9.942846522603637e-07\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 8.431973927300117e-07\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 4.390954281686234e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 4.349395061365779e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 4.007282361540554e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 9.056328551410597e-07\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 8.43197392544123e-07\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 9.528032345860704e-07\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 2.994429634126747e-06\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 5.324358223186472e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 5.128441565403461e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 8.179356130459413e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 9.528032350673736e-07\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 8.431973927300117e-07\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 4.390954281686234e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 4.349395061365779e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 4.0125834318239955e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 9.164331008379704e-07\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 8.43197392544123e-07\n",
      "Model_name: Lasso\n",
      "Average RMSE for Lasso: 1.0368366504223367e-06\n",
      "Model_name: SVR\n",
      "Average RMSE for SVR: 4.3026050311141735e-06\n",
      "Model_name: KNN\n",
      "Average RMSE for KNN: 5.869260650286763e-07\n",
      "Model_name: Random Forest\n",
      "Average RMSE for Random Forest: 5.705738563433915e-07\n",
      "Model_name: AdaBoost\n",
      "Average RMSE for AdaBoost: 9.946025084099586e-07\n",
      "Model_name: XGBoost\n",
      "Average RMSE for XGBoost: 1.0368366505880418e-06\n",
      "Model_name(no clustering): Lasso\n",
      "Average RMSE for Lasso without clustering: 8.431973927300117e-07\n",
      "Model_name(no clustering): SVR\n",
      "Average RMSE for SVR without clustering: 4.390954281686234e-06\n",
      "Model_name(no clustering): KNN\n",
      "Average RMSE for KNN without clustering: 4.349395061365779e-07\n",
      "Model_name(no clustering): Random Forest\n",
      "Average RMSE for Random Forest without clustering: 3.999460583043166e-07\n",
      "Model_name(no clustering): AdaBoost\n",
      "Average RMSE for AdaBoost without clustering: 9.113442873515658e-07\n",
      "Model_name(no clustering): XGBoost\n",
      "Average RMSE for XGBoost without clustering: 8.43197392544123e-07\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error,make_scorer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "import numpy as np\n",
    "\n",
    "# Function to load and preprocess dataset for each gate\n",
    "def load_and_preprocess_data(gate_name):\n",
    "    if gate_name=='INVERTER':\n",
    "        filename='INVERTER/INVERTER_leakage.csv'\n",
    "    elif gate_name=='XOR':\n",
    "        filename='XOR/XOR_leakage.csv'\n",
    "    elif gate_name=='AND_2':\n",
    "        filename='AND/AND_2_leakage.csv'\n",
    "    elif gate_name=='AND_3':\n",
    "        filename='AND_3/AND_3_leakage.csv'\n",
    "    elif gate_name=='OR_2':\n",
    "        filename='OR/OR_2_leakage.csv'\n",
    "    data = pd.read_csv(filename)  # Assuming dataset files are named accordingly\n",
    "    X = data.drop(columns=['Leakage_power'])  # Assuming 'Leakage_Power' is the target column\n",
    "    y = data['Leakage_power']\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    return X_scaled, y\n",
    "\n",
    "# Function for Pearson correlation dimension reduction\n",
    "def pearson_correlation_reduction(X):\n",
    "    pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "    X_reduced = pca.fit_transform(X)\n",
    "    return X_reduced\n",
    "\n",
    "# Function for GMM clustering-based dataset splitting with dynamic number of clusters\n",
    "def gmm_clustering_split(X, y, max_clusters=10):\n",
    "    best_bic = np.inf\n",
    "    best_gmm = None\n",
    "    best_cluster_labels = None\n",
    "    \n",
    "    for n_components in range(1, max_clusters + 1):\n",
    "        gmm = GaussianMixture(n_components=n_components, random_state=42)\n",
    "        cluster_labels = gmm.fit_predict(X)\n",
    "        bic = gmm.bic(X)\n",
    "        \n",
    "        if bic < best_bic:\n",
    "            best_bic = bic\n",
    "            best_gmm = gmm\n",
    "            best_cluster_labels = cluster_labels\n",
    "    \n",
    "    X_clusters, y_clusters = {}, {}\n",
    "    for label in np.unique(best_cluster_labels):\n",
    "        X_cluster = X[best_cluster_labels == label]\n",
    "        y_cluster = y[best_cluster_labels == label]\n",
    "        X_clusters[label] = X_cluster\n",
    "        y_clusters[label] = y_cluster\n",
    "    \n",
    "    return X_clusters, y_clusters\n",
    "\n",
    "# Function for feature selection based on mutual information\n",
    "def feature_selection(X_train, y_train, num_features):\n",
    "    mi_scores = mutual_info_regression(X_train, y_train)\n",
    "    selected_features = np.argsort(mi_scores)[::-1][:num_features]  # Select top 'num_features' features based on mutual information\n",
    "    return selected_features\n",
    "\n",
    "\n",
    "# Function for model selection based on RMSE\n",
    "def model_selection(models, X_train, y_train):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    best_rmse = float('inf')\n",
    "    best_model = None\n",
    "    model_rmse_list_clustering = []\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=kf, scoring=make_scorer(mean_squared_error))\n",
    "        rmse = np.sqrt(np.mean(scores))\n",
    "        print(\"Model_name:\",model_name)\n",
    "        print(f'Average RMSE for {model_name}: {rmse}')\n",
    "        model_rmse_list_clustering.append({'Model_name': model_name, 'RMSE': rmse})\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_model = model\n",
    "    \n",
    "    return best_model,model_rmse_list_clustering\n",
    "\n",
    "def model_selection_no_clustering(models, X_train, y_train):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    best_rmse = float('inf')\n",
    "    best_model = None\n",
    "    model_rmse_list_no_clustering = []\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=kf, scoring=make_scorer(mean_squared_error))\n",
    "        rmse = np.sqrt(np.mean(scores))\n",
    "        print(\"Model_name(no clustering):\",model_name)\n",
    "        print(f'Average RMSE for {model_name} without clustering: {rmse}')\n",
    "        model_rmse_list_no_clustering.append({'Model_name': model_name, 'RMSE': rmse})\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_model = model\n",
    "    \n",
    "    return best_model,model_rmse_list_no_clustering\n",
    "\n",
    "# Function for weighted ensemble\n",
    "def weighted_ensemble(predictions, weights):\n",
    "    total_weight = sum(weights)\n",
    "    ensemble_prediction = np.zeros_like(predictions[0])\n",
    "    \n",
    "    for prediction, weight in zip(predictions, weights):\n",
    "        ensemble_prediction += prediction * (weight / total_weight)\n",
    "    \n",
    "    return ensemble_prediction\n",
    "\n",
    "# Define gate names\n",
    "gate_names = ['INVERTER','XOR','AND_2','AND_3','OR_2']\n",
    "\n",
    "# Load, preprocess, dimension reduction, and split datasets for each gate\n",
    "gate_datasets = {}\n",
    "models = {}\n",
    "\n",
    "num_features=15\n",
    "\n",
    "for gate_name in gate_names:\n",
    "    X_gate, y_gate = load_and_preprocess_data(gate_name)\n",
    "    \n",
    "    # Splitting data into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_gate, y_gate, test_size=0.01, random_state=42)\n",
    "    \n",
    "    # Apply Pearson correlation dimension reduction\n",
    "    X_reduced_train = pearson_correlation_reduction(X_train)\n",
    "    X_reduced_test = pearson_correlation_reduction(X_test)\n",
    "    \n",
    "    # Split dataset using GMM clustering\n",
    "    X_clusters, y_clusters = gmm_clustering_split(X_reduced_train, y_train)\n",
    "    print('Optimal Cluster for {gate_name} using BIC score',len(X_clusters))\n",
    "    \n",
    "    # Feature selection and model selection for each cluster\n",
    "    cluster_models = {}\n",
    "    for label, X_cluster in X_clusters.items():\n",
    "        y_cluster = y_clusters[label]\n",
    "        \n",
    "        # Feature selection\n",
    "        selected_features = feature_selection(X_cluster, y_cluster,num_features=num_features)\n",
    "        X_selected = X_cluster[:, selected_features]\n",
    "        \n",
    "        # Model selection\n",
    "        lasso = Lasso().fit(X_selected, y_cluster)\n",
    "        svr = SVR().fit(X_selected, y_cluster)\n",
    "        knn = KNeighborsRegressor().fit(X_selected, y_cluster)\n",
    "        rf = RandomForestRegressor(n_estimators=100, max_features='sqrt').fit(X_selected, y_cluster)\n",
    "        ada_boost = AdaBoostRegressor().fit(X_selected, y_cluster)\n",
    "        xgb_reg = xgb.XGBRegressor().fit(X_selected, y_cluster)\n",
    "        \n",
    "        models_for_cluster = {'Lasso': lasso, 'SVR': svr, 'KNN': knn, 'Random Forest': rf, 'AdaBoost': ada_boost, 'XGBoost': xgb_reg}\n",
    "        best_model,list_clustering = model_selection(models_for_cluster, X_selected, y_cluster)\n",
    "        best_model_no_cluster,list_no_clustering = model_selection_no_clustering(models_for_cluster,X_reduced_train, y_train)\n",
    "        \n",
    "        cluster_models[label] = best_model\n",
    "    \n",
    "    models[gate_name] = cluster_models\n",
    "    \n",
    "    # Save the datasets for later use\n",
    "    gate_datasets[gate_name] = {'X_clusters': X_clusters, 'y_clusters': y_clusters}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Model_name': 'Lasso', 'RMSE': 8.431973927300117e-07}, {'Model_name': 'SVR', 'RMSE': 4.390954281686234e-06}, {'Model_name': 'KNN', 'RMSE': 4.349395061365779e-07}, {'Model_name': 'Random Forest', 'RMSE': 3.999460583043166e-07}, {'Model_name': 'AdaBoost', 'RMSE': 9.113442873515658e-07}, {'Model_name': 'XGBoost', 'RMSE': 8.43197392544123e-07}]\n",
      "[{'Model_name': 'Lasso', 'RMSE': 1.0368366504223367e-06}, {'Model_name': 'SVR', 'RMSE': 4.3026050311141735e-06}, {'Model_name': 'KNN', 'RMSE': 5.869260650286763e-07}, {'Model_name': 'Random Forest', 'RMSE': 5.705738563433915e-07}, {'Model_name': 'AdaBoost', 'RMSE': 9.946025084099586e-07}, {'Model_name': 'XGBoost', 'RMSE': 1.0368366505880418e-06}]\n"
     ]
    }
   ],
   "source": [
    "print(list_no_clustering)\n",
    "print(list_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_leakage_power(gate_name, X_test):\n",
    "    # Load cluster data for the specified gate\n",
    "    X_clusters = gate_datasets[gate_name]['X_clusters']\n",
    "    y_clusters = gate_datasets[gate_name]['y_clusters']\n",
    "    \n",
    "    # Initialize lists to store predictions and weights for each cluster\n",
    "    cluster_predictions = []\n",
    "    cluster_weights = []\n",
    "    \n",
    "    # Reshape X_test to maintain 2-dimensional shape\n",
    "    X_test_reshaped = X_test.reshape(1, -1)\n",
    "    \n",
    "    # Iterate over each cluster\n",
    "    for label, X_cluster in X_clusters.items():\n",
    "        # Use parameters to select relevant features\n",
    "        selected_features = feature_selection(X_cluster, y_clusters[label], num_features=num_features)\n",
    "        # Reshape X_test to maintain 2-dimensional shape\n",
    "        X_selected = X_test_reshaped[:, selected_features]\n",
    "        \n",
    "        # Get the model for the cluster\n",
    "        model = models[gate_name][label]\n",
    "        \n",
    "        # Make predictions for the cluster\n",
    "        cluster_prediction = model.predict(X_selected)\n",
    "        \n",
    "        # Append predictions and weights for weighted ensemble\n",
    "        cluster_predictions.append(cluster_prediction)\n",
    "        cluster_weights.append(len(X_cluster))  # Using the number of samples in the cluster as weight\n",
    "    \n",
    "    # Perform weighted ensemble for all clusters\n",
    "    ensemble_prediction = weighted_ensemble(cluster_predictions, cluster_weights)\n",
    "    return ensemble_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def get_c499_true_leakage(filename):\n",
    "    text = os.popen(f\"ngspice {filename}\").read()\n",
    "    voltage_pattern = re.compile(r\"v\\((\\w+)\\) = ([\\d\\.\\-\\+e]+)\")\n",
    "    current_pattern = re.compile(r\"i\\((\\w+)\\) = ([\\d\\.\\-\\+e]+)\")\n",
    "\n",
    "    voltages = []\n",
    "    currents = []\n",
    "\n",
    "    for match in re.finditer(voltage_pattern, text):\n",
    "        voltages.append((match.group(1), float(match.group(2))))\n",
    "\n",
    "    for match in re.finditer(current_pattern, text):\n",
    "        currents.append((match.group(1), float(match.group(2))))\n",
    "\n",
    "    leakage=0\n",
    "    \n",
    "    for v,i in zip(voltages,currents):\n",
    "        leakage+=v[1]*i[1]\n",
    "    \n",
    "    return leakage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_combinations = {\n",
    "    'XOR' : [\n",
    "('in1', 'in5'), ('in9', 'in13'), ('in17', 'in21'), ('in25', 'in29'),\n",
    "('in33', 'in37'), ('in41', 'in45'), ('in49', 'in53'), ('in57', 'in61'),\n",
    "('in65', 'in69'), ('in73', 'in77'), ('in81', 'in85'), ('in89', 'in93'),\n",
    "('in97', 'in101'), ('in105', 'in109'), ('in113', 'in117'), ('in121', 'in125'),\n",
    "('in1', 'in17'), ('in5', 'in21'), ('in9', 'in25'), ('in13', 'in29'),\n",
    "('in65', 'in81'), ('in69', 'in85'), ('in73', 'in89'), ('in77', 'in93'),\n",
    "('in33', 'in49'), ('in37', 'in53'), ('in41', 'in57'), ('in45', 'in61'),\n",
    "('in97', 'in113'), ('in101', 'in117'), ('in105', 'in121'), ('in109', 'in125'),\n",
    "('in1', 'in5'), ('in9', 'in13'), ('in17', 'in21'), ('in25', 'in29'),\n",
    "('in33', 'in37'), ('in41', 'in45'), ('in49', 'in53'), ('in57', 'in61'),\n",
    "('in1', 'in17'), ('in5', 'in21'), ('in9', 'in25'), ('in13', 'in29'),\n",
    "('in65', 'in81'), ('in69', 'in85'), ('in73', 'in89'), ('in77', 'in93'),\n",
    "('in33', 'in49'), ('in37', 'in53'), ('in41', 'in57'), ('in45', 'in61'),\n",
    "('in97', 'in113'), ('in101', 'in117'), ('in105', 'in121'), ('in109', 'in125'),\n",
    "('XA__0', 'XA__1'), ('XA__2', 'XA__3'), ('XA__4', 'XA__5'), ('XA__6', 'XA__7'),\n",
    "('XA__8', 'XA__9'), ('XA__10', 'XA__11'), ('XA__12', 'XA__13'), ('XA__14', 'XA__15'),\n",
    "('in1', 'in5'), ('in9', 'in13'), ('in17', 'in21'), ('in25', 'in29'),\n",
    "('in33', 'in37'), ('in41', 'in45'), ('in49', 'in53'), ('in57', 'in61'),\n",
    "('in1', 'in17'), ('in5', 'in21'), ('in9', 'in25'), ('in13', 'in29'),\n",
    "('in65', 'in81'), ('in69', 'in85'), ('in73', 'in89'), ('in77', 'in93'),\n",
    "('in33', 'in49'), ('in37', 'in53'), ('in41', 'in57'), ('in45', 'in61'),\n",
    "('in97', 'in113'), ('in101', 'in117'), ('in105', 'in121'), ('in109', 'in125'),\n",
    "('XB__0', 'XC__0'), ('XB__1', 'XC__1'), ('XB__2', 'XC__2'), ('XB__3', 'XC__3'),\n",
    "('XB__4', 'XC__4'), ('XB__5', 'XC__5'), ('XB__6', 'XC__6'), ('XB__7', 'XC__7'),\n",
    "('F__0', 'F__1'), ('F__2', 'F__3'), ('F__0', 'F__2'), ('F__1', 'F__3'),\n",
    "('F__4', 'F__5'), ('F__6', 'F__7'), ('F__4', 'F__6'), ('F__5', 'F__7'),\n",
    "('G__4', 'H__0'), ('G__5', 'H__1'), ('G__6', 'H__2'), ('G__7', 'H__3'),\n",
    "('G__0', 'H__4'), ('G__1', 'H__5'), ('G__2', 'H__6'), ('G__3', 'H__7'),\n",
    "('XD__0', 'XE__0'), ('XD__1', 'XE__1'), ('XD__2', 'XE__2'), ('XD__3', 'XE__3'),\n",
    "('XD__4', 'XE__4'), ('XD__5', 'XE__5'), ('XD__6', 'XE__6'), ('XD__7', 'XE__7'),\n",
    "('XD__0', 'XE__0'), ('XD__1', 'XE__1'), ('XD__2', 'XE__2'), ('XD__3', 'XE__3'),\n",
    "('XD__4', 'XE__4'), ('XD__5', 'XE__5'), ('XD__6', 'XE__6'), ('XD__7', 'XE__7')\n",
    "],\n",
    "    'OR_2': [\n",
    "    ('T__0', 'T__1'), ('T__4', 'T__5'), ('T__2', 'T__3'), ('T__6', 'T__7')\n",
    "],\n",
    "    'AND_2': [\n",
    "    ('W__0', 'S__0'), ('W__0', 'S__1'), ('W__0', 'S__2'), ('W__0', 'S__3'),\n",
    "    ('W__1', 'S__0'), ('W__1', 'S__1'), ('W__1', 'S__2'), ('W__1', 'S__3'),\n",
    "    ('W__2', 'S__0'), ('W__2', 'S__1'), ('W__2', 'S__2'), ('W__2', 'S__3'),\n",
    "    ('W__3', 'S__0'), ('W__3', 'S__1'), ('W__3', 'S__2'), ('W__3', 'S__3'),\n",
    "    ('W__4', 'S__4'), ('W__4', 'S__5'), ('W__4', 'S__6'), ('W__4', 'S__7'),\n",
    "    ('W__5', 'S__4'), ('W__5', 'S__5'), ('W__5', 'S__6'), ('W__5', 'S__7'),\n",
    "    ('W__6', 'S__4'), ('W__6', 'S__5'), ('W__6', 'S__6'), ('W__6', 'S__7'),\n",
    "    ('W__7', 'S__4'), ('W__7', 'S__5'), ('W__7', 'S__6'), ('W__7', 'S__7'),\n",
    "    ('T0_temp', 'S__3'), ('T1_temp', 'S3B__0'), ('T2_temp', 'S3B__1'), ('T3_temp', 'S3B__2'),\n",
    "    ('T4_temp', 'S__7'), ('T5_temp', 'S7B__0'), ('T6_temp', 'S7B__1'), ('T7_temp', 'S7B__2')\n",
    "],\n",
    "    'AND_3': [\n",
    "    ('S0B__0', 'S1B__0', 'S2B__0'), ('S0B__1', 'S1B__1', 'S__2'),\n",
    "    ('S0B__2', 'S__1', 'S2B__1'), ('S__0', 'S1B__2', 'S2B__2'),\n",
    "    ('S4B__0', 'S5B__0', 'S6B__0'), ('S4B__1', 'S5B__1', 'S__6'),\n",
    "    ('S4B__2', 'S__5', 'S6B__1'), ('S__4', 'S5B__2', 'S6B__2'),\n",
    "    ('S__4', 'S5B__3', 'S__6'), ('S7B__3', 'U__0', 'W__0'),\n",
    "    ('S__4', 'S5B__4', 'S6B__3'), ('S__7', 'U__0', 'W__1'),\n",
    "    ('S4B__3', 'S__5', 'S__6'), ('S7B__4', 'U__0', 'W__2'),\n",
    "    ('S4B__4', 'S__5', 'S6B__4'), ('S__7', 'U__0', 'W__3'),\n",
    "    ('S__0', 'S1B__3', 'S__2'), ('S3B__3', 'U__1', 'W__4'),\n",
    "    ('S__0', 'S1B__4', 'S2B__3'), ('S__3', 'U__1', 'W__5'),\n",
    "    ('S0B__3', 'S__1', 'S__2'), ('S3B__4', 'U__1', 'W__6'),\n",
    "    ('S0B__4', 'S__1', 'S2B__4'), ('S__3', 'U__1', 'W__7')\n",
    "],\n",
    "    'INVERTER': [\n",
    "    'S__0', 'S__1', 'S__2', 'S__3', 'S__4', 'S__5', 'S__6','S__7'\n",
    "]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def get_c499_estimate_leakage(filename,to_skip=1):\n",
    "    text = os.popen(f\"ngspice {filename}\").read()\n",
    "    voltage_pattern = re.compile(r\"v\\((\\w+)\\) = ([\\d\\.\\-\\+e]+)\")\n",
    "\n",
    "    voltages = []\n",
    "\n",
    "    for match in re.finditer(voltage_pattern, text):\n",
    "        voltages.append((match.group(1), float(match.group(2))))\n",
    "        \n",
    "    voltages_dict = dict(voltages)\n",
    "    \n",
    "    cur_row=0\n",
    "    \n",
    "    estimate_leakage_list=[]\n",
    "    \n",
    "    with open('C499/C499_true_leakage.csv', newline='') as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        \n",
    "        for row in csvreader:\n",
    "            if cur_row<to_skip:\n",
    "                cur_row+=1\n",
    "                continue\n",
    "            estimate_leakage=0\n",
    "            for gate_name in gate_names:\n",
    "                for inputs in gate_combinations[gate_name]:\n",
    "                    parameters=[]\n",
    "                    if gate_name=='INVERTER':\n",
    "                        parameters.append(voltages_dict[inputs.lower()])\n",
    "                    elif gate_name=='XOR' or gate_name=='AND_2' or gate_name=='OR_2':\n",
    "                        parameters.append(voltages_dict[inputs[0].lower()])\n",
    "                        parameters.append(voltages_dict[inputs[1].lower()])\n",
    "                    else:\n",
    "                        parameters.append(voltages_dict[inputs[0].lower()])\n",
    "                        parameters.append(voltages_dict[inputs[1].lower()])\n",
    "                        parameters.append(voltages_dict[inputs[2].lower()])\n",
    "                    parameters.extend(row[1:-1])  #Change this depending on number of inputs in true leakage\n",
    "                    parameters=[float(x) for x in parameters]\n",
    "                    val=predict_leakage_power(gate_name,np.array(parameters))\n",
    "                    estimate_leakage+=val\n",
    "            \n",
    "            estimate_leakage_list.append(estimate_leakage)\n",
    "    \n",
    "    return estimate_leakage_list                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Starting dynamic gmin stepping\n",
      "Trying gmin =   1.0000E-03 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-04 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-05 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-06 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-07 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-08 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-09 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-10 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-11 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-12 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-13 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-14 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-15 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-16 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-17 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-18 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-19 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-20 Note: One successful gmin step\n",
      "Trying gmin =   1.0000E-20 Note: One successful gmin step\n",
      "Note: Dynamic gmin stepping completed\n"
     ]
    }
   ],
   "source": [
    "estimate_leakage_list=get_c499_estimate_leakage('C499/c499_estimate_leakage.net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the existing CSV file into a DataFrame\n",
    "existing_data = pd.read_csv('C499/c499_true_leakage.csv')\n",
    "\n",
    "# Create a new column 'Estimate_leakage' and assign values from estimate_leakage_list\n",
    "existing_data['Estimate_leakage'] = estimate_leakage_list\n",
    "\n",
    "# Save the DataFrame with the new column back to a CSV file\n",
    "existing_data.to_csv('Final_leakage.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9315904798240491\n"
     ]
    }
   ],
   "source": [
    "# Load the existing CSV file into a DataFrame\n",
    "existing_data = pd.read_csv('C499/c499_true_leakage.csv')\n",
    "\n",
    "# Create a new column 'Estimate_leakage' and assign values from estimate_leakage_list\n",
    "y_test=existing_data['Leakage_power']\n",
    "\n",
    "r2=r2_score(np.array(y_test).reshape(-1,1),np.array(estimate_leakage_list).reshape(-1,1))\n",
    "print(r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
